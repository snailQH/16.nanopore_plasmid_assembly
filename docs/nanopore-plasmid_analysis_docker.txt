#Planning for the whole pipeline
we are developing a docker image, which will be used to do plasmid sequencing based on nanopore sequenced fastq file(which will be a fast_pass folder, just like the output of a nanopore sequencing run);
step1: Get fast_pass folder from nanopore sequencing run;
step2: Assembly all the fastq files in the fast_pass folder, using flye or canu; Each sub folder in fast_pass means a different plasmid sample. This step will generate a fasta file for each plasmid sample;
step3: Use 


(base) bioinfo@ampseq01:~$ docker pull ubuntu 
Using default tag: latest
latest: Pulling from library/ubuntu
20043066d3d5: Pull complete 
Digest: sha256:c35e29c9450151419d9448b0fd75374fec4fff364a27f176fb458d472dfc9e54
Status: Downloaded newer image for ubuntu:latest
docker.io/library/ubuntu:latest
(base) bioinfo@ampseq01:~$ 

docker run --rm -it -v /data4:/data4 ubuntu
(base) bioinfo@ampseq01:~$ cp -r  /opt/scripts /data4/liqh/scripts-test
root@4705e76e34de:/# cp -r /data4/liqh/scripts-test /opt/scripts
apt update
apt install -y git 


#https://github.com/hyraxbio/hyraxAbif?tab=readme-ov-file
cd /opt/
git clone https://github.com/hyraxbio/hyraxAbif.git
cd /opt/hyraxAbif
apt-get install -y haskell-stack
make build
#æŠ¥é”™,åœ¨stack.yaml fileä¸­æ·»åŠ é¢å¤–2è¡Œ
extra-deps:
  - stm-2.5.3.1@sha256:421b57c9cdf55b4977e9445336be3895ba0c8d92b6ec6e474f140e173270d9dd,2443
  - verset-0.0.1.11

#å†æ‰§è¡Œæ›´æ–°:
stack update
stack build

#å†ç¼–è¯‘:
#root@4705e76e34de:/opt/hyraxAbif# 
make build
STACK_YAML="stack.yaml" stack build hyraxAbif --no-run-tests
Getting project config file from STACK_YAML environment

#test function of hyraxAbif: 
root@4705e76e34de:/opt/hyraxAbif# cp /data4/liqh/scripts-test/U*fasta ./demo_data/
root@4705e76e34de:/opt/hyraxAbif# ll demo_data/
total 40
drwxr-xr-x  2 root root 4096 Dec  1 06:51 ./
drwxr-xr-x 10 root root 4096 Dec  1 06:41 ../
-rwxr-xr-x  1 root root 6821 Dec  1 06:51 UPA42701.final.fasta
-rwxr-xr-x  1 root root 6858 Dec  1 06:51 UPA42703.final.fasta*
-rwxr-xr-x  1 root root 7493 Dec  1 06:51 UPA42705.final.fasta*
-rwxr-xr-x  1 root root 6821 Dec  1 06:51 UPA42742.final.fasta*
root@4705e76e34de:/opt/hyraxAbif# 
root@4705e76e34de:/opt/hyraxAbif# apt install -y python3 python3-pip
root@4705e76e34de:/opt/hyraxAbif# ln -s /usr/bin/python3 /usr/local/bin/python
#pip3 install biopython ,  error
root@4705e76e34de:/opt/hyraxAbif# apt-get install -y python3-biopython


python /opt/scripts/split_plasmid_fasta.py demo_data/UPA42701.final.fasta demo_data/UPA42701_2k_fragmented/
#[OK] Wrote demo_data/UPA42701_2k_fragmented/1.0_part1.fasta (2000 bp)
#[OK] Wrote demo_data/UPA42701_2k_fragmented/1.0_part2.fasta (2000 bp)
#[OK] Wrote demo_data/UPA42701_2k_fragmented/1.0_part3.fasta (2000 bp)
#[OK] Wrote demo_data/UPA42701_2k_fragmented/1.0_part4.fasta (814 bp)

#å‡çº§è„šæœ¬;
python /opt/scripts/split_plasmid_fasta.py --input demo_data/UPA42701.final.fasta --outdir demo_data/UPA42701_2k_fragmented  --sample UPA42701  --size 2000
[OK] Wrote demo_data/UPA42701_2k_fragmented/UPA42701_1.0_part1.fasta (2000 bp)
[OK] Wrote demo_data/UPA42701_2k_fragmented/UPA42701_1.0_part2.fasta (2000 bp)
[OK] Wrote demo_data/UPA42701_2k_fragmented/UPA42701_1.0_part3.fasta (2000 bp)
[OK] Wrote demo_data/UPA42701_2k_fragmented/UPA42701_1.0_part4.fasta (814 bp)


/opt/hyraxAbif/hyraxAbif-exe gen demo_data//UPA42701_2k_fragmented demo_data/UPA42701_2k_fragmented_ab1  
root@4705e76e34de:/opt/hyraxAbif# ll demo_data/UPA42701_2k_fragmented_ab1
total 568
drwxr-xr-x 2 root root   4096 Dec  1 07:08 ./
drwxr-xr-x 5 root root   4096 Dec  1 06:59 ../
-rw-r--r-- 1 root root 166591 Dec  1 07:07 UPA42701_1.0_part1.ab1
-rw-r--r-- 1 root root 166591 Dec  1 07:07 UPA42701_1.0_part2.ab1
-rw-r--r-- 1 root root 166591 Dec  1 07:07 UPA42701_1.0_part3.ab1
-rw-r--r-- 1 root root  68153 Dec  1 07:07 UPA42701_1.0_part4.ab1

#finish installing hyraxAbif which will be used to generate ab1 files based on input fasta files.


##############apt install nanofiltapt install nanofiltapt install nanofiltapt install nanofilt
#root@4705e76e34de:/opt/hyraxAbif# 
apt install -y python3-matplotlib nanofilt

#filter heading base and low quality base,short reads;
gunzip -c reads.fastq.gz | NanoFilt -l 100 -q 12 --headcrop 50 | gzip > ${SAMPLE}.filtered.fastq.gz




python3 /opt/scripts/generate_complete_reports.py -d ../output -o ../results --project-id final_reports





##########################################################################################################################################################################################################################################################################
(base) bioinfo@ampseq01:~$ tree  /mnt/AMPSEQ-SFTP/sftp-home/ct_ampseq/upload/Plasmid/fast_pass
/mnt/AMPSEQ-SFTP/sftp-home/ct_ampseq/upload/Plasmid/fast_pass
â”œâ”€â”€ U0022772G0-13-UPA53974
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U0022772G0-13-UPA53974_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U0022772G0-13-UPA53974_f4cf4181_c5be703c_1.fastq.gz
â”œâ”€â”€ U1089XVPG0-144-UPA53579
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U1089XVPG0-144-UPA53579_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U1089XVPG0-144-UPA53579_f4cf4181_c5be703c_1.fastq.gz
â”œâ”€â”€ U1335061G0-105-UPA52629
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U1335061G0-105-UPA52629_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U1335061G0-105-UPA52629_f4cf4181_c5be703c_1.fastq.gz
â”œâ”€â”€ U561P334G0-3-UPA51888
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U561P334G0-3-UPA51888_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U561P334G0-3-UPA51888_f4cf4181_c5be703c_1.fastq.gz
â”œâ”€â”€ U6418977G0-33-UPA52775
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U6418977G0-33-UPA52775_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U6418977G0-33-UPA52775_f4cf4181_c5be703c_1.fastq.gz
â”œâ”€â”€ U7709840G0-1-UPA54110
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U7709840G0-1-UPA54110_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U7709840G0-1-UPA54110_f4cf4181_c5be703c_1.fastq.gz
â””â”€â”€ U8461027G0-775-UPA51877
    â”œâ”€â”€ PBG13417_pass_U8461027G0-775-UPA51877_f4cf4181_c5be703c_0.fastq.gz
    â””â”€â”€ PBG13417_pass_U8461027G0-775-UPA51877_f4cf4181_c5be703c_1.fastq.gz

8 directories, 14 files
(base) bioinfo@ampseq01:~$ cp -r  /mnt/AMPSEQ-SFTP/sftp-home/ct_ampseq/upload/Plasmid/fast_pass /data4/liqh/scripts-test/


##########################################################################################################################################################################################################################################################################




éœ€è¦:
rawfastq;
fasta,
gbk,
ä¸€ä»£æµ‹åºçš„ä¿¡å·å›¾(ab1);
pdf size-distribution(ç›®å‰å®¢æˆ·ä¸»è¦è¦çš„),
ç„¶åè¿˜æœ‰coverage;
ç›®å‰åªæœ‰ä¸€ä¸ªå®¢æˆ·, ç”Ÿæˆäº†éƒ½åœ¨ä¸€ä¸ªfolderä¸­;
æŒ‰ç…§å®¢æˆ·å, æœ‰ç‹¬ç«‹çš„folder, ç„¶åæŒ‰ç…§æ—¥é¡¹ç›®å·, å†æœ‰å­ç›®å½•(æ ¹æ®order-idæ¥å‘½å, å†åŠ å®¢æˆ·å,å†åŠ æ—¥æœŸ, ID123-QHLI-112525);

input data: plasmid/fast-pass, å°±æ˜¯å’Œä¸‹æœºæ•°æ®ä¸€æ ·çš„ç›®å½•;
åœ¨å®ƒçš„å­folderä¸­;
```bash
(base) bioinfo@ampseq01:/mnt/AMPSEQ-SFTP/sftp-home/ct_ampseq/upload/Plasmid/fast_pass$ tree ./
./
â”œâ”€â”€ U0022772G0-13-UPA53974
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U0022772G0-13-UPA53974_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U0022772G0-13-UPA53974_f4cf4181_c5be703c_1.fastq.gz
â”œâ”€â”€ U1089XVPG0-144-UPA53579
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U1089XVPG0-144-UPA53579_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U1089XVPG0-144-UPA53579_f4cf4181_c5be703c_1.fastq.gz
â”œâ”€â”€ U1335061G0-105-UPA52629
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U1335061G0-105-UPA52629_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U1335061G0-105-UPA52629_f4cf4181_c5be703c_1.fastq.gz
â”œâ”€â”€ U561P334G0-3-UPA51888
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U561P334G0-3-UPA51888_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U561P334G0-3-UPA51888_f4cf4181_c5be703c_1.fastq.gz
â”œâ”€â”€ U6418977G0-33-UPA52775
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U6418977G0-33-UPA52775_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U6418977G0-33-UPA52775_f4cf4181_c5be703c_1.fastq.gz
â”œâ”€â”€ U7709840G0-1-UPA54110
â”‚Â Â  â”œâ”€â”€ PBG13417_pass_U7709840G0-1-UPA54110_f4cf4181_c5be703c_0.fastq.gz
â”‚Â Â  â””â”€â”€ PBG13417_pass_U7709840G0-1-UPA54110_f4cf4181_c5be703c_1.fastq.gz
â””â”€â”€ U8461027G0-775-UPA51877
    â”œâ”€â”€ PBG13417_pass_U8461027G0-775-UPA51877_f4cf4181_c5be703c_0.fastq.gz
    â””â”€â”€ PBG13417_pass_U8461027G0-775-UPA51877_f4cf4181_c5be703c_1.fastq.gz

8 directories, 14 files
(base) bioinfo@ampseq01:/mnt/AMPSEQ-SFTP/sftp-home/ct_ampseq/upload/Plasmid/fast_pass$ 


##########################################################################################################################################################################################################################################################################
å¥½â€”â€”æˆ‘æŠŠä¹‹å‰çš„ QC-only è„šæœ¬æ‰©å±•æˆå®Œæ•´ã€å¯æ‰¹é‡è¿è¡Œã€æŒ‰æ ·å“è¾“å‡ºç‹¬ç«‹ç»“æœç›®å½•çš„ç”Ÿäº§çº§ Bash pipelineï¼Œè¦†ç›–ä½ è¦çš„ï¼š
QCï¼ˆNanoFiltï¼‰â†’ å¯é€‰ Filtlong â†’ ç»„è£…ï¼ˆFlyeï¼‰â†’ åœ†åŒ–ï¼ˆCirclatorï¼‰â†’ Racon å¤šè½®æŠ›å…‰ â†’ Medaka æœ€ç»ˆæŠ›å…‰ â†’ æ³¨é‡Šï¼ˆProkkaï¼‰â†’ æ˜ å°„è´¨æ§ â†’ æ€»ç»“è¡¨ã€‚

è„šæœ¬è¦ç‚¹ï¼ˆè®¾è®¡åŸåˆ™ï¼‰ï¼š
	â€¢	æ¥å—ä¸€ä¸ªè¾“å…¥ç›®å½•ï¼ˆé»˜è®¤ fast_passï¼‰ï¼Œæ¯ä¸ªæ ·å“ä¸ºå­ç›®å½•ï¼Œå­ç›®å½•å†…å¯å«å¤šä¸ª *.fastq.gzã€‚
	â€¢	æ¯ä¸ªæ ·å“å•ç‹¬è¾“å‡ºåˆ° ${OUTDIR}/${SAMPLE} ä¸‹ï¼Œæ‰€æœ‰ä¸­é—´äº§ç‰©ä¸æœ€ç»ˆç»“æœéƒ½ä¿ç•™ï¼ˆä¾¿äºå®¡è®¡ï¼‰ã€‚
	â€¢	å‚æ•°åŒ–ï¼šå¯è®¾ç½® headcropã€min_lenã€min_qã€genome_sizeã€racon_roundsã€threadsã€medaka_model ç­‰ã€‚
	â€¢	å¤±è´¥å³ä¸­æ–­ï¼ˆset -euo pipefailï¼‰ï¼Œå¹¶å¸¦æ¸…æ™°æ—¥å¿—ã€‚
	â€¢	åœ¨å¼€å§‹å‰æ£€æŸ¥æ‰€éœ€å·¥å…·æ˜¯å¦å¯ç”¨ã€‚
	â€¢	ç”Ÿæˆ summary.tsv æ±‡æ€»æ¯ä¸ªæ ·å“çš„å…³é”®ä¿¡æ¯ã€‚

ä¿å­˜ä¸º plasmid_full_pipeline.sh å¹¶ç»™å¯æ‰§è¡Œæƒé™ chmod +x plasmid_full_pipeline.shï¼Œç›´æ¥æŒ‚åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œã€‚

â¸»

ä½¿ç”¨èŒƒä¾‹

é»˜è®¤è¿è¡Œï¼ˆä½¿ç”¨å½“å‰ç›®å½•ä¸‹ fast_passï¼‰ï¼š

./plasmid_full_pipeline.sh

è‡ªå®šä¹‰è¾“å…¥è¾“å‡ºä¸å‚æ•°ç¤ºä¾‹ï¼š

./plasmid_full_pipeline.sh \
  --indir /mnt/AMPSEQ-SFTP/.../fast_pass \
  --outdir /data/plasmid_results \
  --genome-size 12k \
  --headcrop 50 \
  --min_len 1000 \
  --min_q 12 \
  --racon_rounds 2 \
  --threads 16 \
  --medaka_model r1041_e82_260bps_sup


â¸»

å®Œæ•´è„šæœ¬ï¼šplasmid_full_pipeline.sh

#!/usr/bin/env bash
set -euo pipefail

# plasmid_full_pipeline.sh
# Full ONT plasmid assembly pipeline: NanoFilt -> (Filtlong) -> Flye -> Circlator -> Racon xN -> Medaka -> Prokka -> mapping QC
# Author: ChatGPT
# Usage: ./plasmid_full_pipeline.sh [--indir DIR] [--outdir DIR] [--threads N] ...

# ----------------------
# Default params
# ----------------------
INDIR="fast_pass"
OUTDIR="plasmid_results"
HEADCROP=50
MIN_LEN=100
MIN_Q=12
GENOME_SIZE="10k"
RACON_ROUNDS=2
THREADS=8
MEDAKA_MODEL="r1041_e82_260bps_sup"
USE_FITLONG=false   # set true to run filtlong after NanoFilt
FILTKEEPPCT=90

# ----------------------
# Help / parse args
# ----------------------
print_help(){
  cat <<'HELP'
plasmid_full_pipeline.sh - full nanopore plasmid assembly pipeline

Options:
  --indir DIR          Input directory containing sample subfolders (default: fast_pass)
  --outdir DIR         Output base directory (default: plasmid_results)
  --headcrop N         NanoFilt headcrop (default: 50)
  --min_len N          NanoFilt min read length (default: 100)
  --min_q N            NanoFilt min avg Q (default: 12)
  --genome-size SIZE   Flye genome size estimate (eg. 10k or 12k) (default: 10k)
  --racon_rounds N     Number of Racon rounds (default: 2)
  --threads N          Number of threads (default: 8)
  --medaka_model STR   Medaka model (default: r1041_e82_260bps_sup)
  --use-filtlong       Enable filtlong after NanoFilt (default: disabled)
  --help               Show this help and exit

Example:
  ./plasmid_full_pipeline.sh --indir /mnt/.../fast_pass --outdir /data/plasmid_results --threads 16
HELP
}

# basic arg parsing
while [[ $# -gt 0 ]]; do
  case "$1" in
    --indir) INDIR="$2"; shift 2;;
    --outdir) OUTDIR="$2"; shift 2;;
    --headcrop) HEADCROP="$2"; shift 2;;
    --min_len) MIN_LEN="$2"; shift 2;;
    --min_q) MIN_Q="$2"; shift 2;;
    --genome-size) GENOME_SIZE="$2"; shift 2;;
    --racon_rounds) RACON_ROUNDS="$2"; shift 2;;
    --threads) THREADS="$2"; shift 2;;
    --medaka_model) MEDAKA_MODEL="$2"; shift 2;;
    --use-filtlong) USE_FITLONG=true; shift 1;;
    --help) print_help; exit 0;;
    *) echo "Unknown arg: $1"; print_help; exit 1;;
  esac
done

# ----------------------
# Tool checks
# ----------------------
req_tools=(gunzip NanoFilt filtlong flye circlator minimap2 samtools racon medaka_consensus prokka)
missing=()
for t in "${req_tools[@]}"; do
  if ! command -v $t &>/dev/null; then
    missing+=("$t")
  fi
done

if [[ ${#missing[@]} -ne 0 ]]; then
  echo "[ERROR] Missing required tools: ${missing[*]}"
  echo "Please install them before running the pipeline."
  exit 1
fi

# ----------------------
# Setup output structure
# ----------------------
mkdir -p "${OUTDIR}"
SUMMARY="${OUTDIR}/summary.tsv"
echo -e "sample\tfinal_fasta\tcontig_count\tmax_contig_len\tassembly_method\tnotes" > "${SUMMARY}"

echo "[INFO] Input dir: ${INDIR}"
echo "[INFO] Output dir: ${OUTDIR}"
echo "[INFO] Threads: ${THREADS}"
echo "[INFO] NanoFilt: headcrop=${HEADCROP}, min_len=${MIN_LEN}, min_q=${MIN_Q}"
echo "[INFO] Flye genome size: ${GENOME_SIZE}"
echo "[INFO] Racon rounds: ${RACON_ROUNDS}"
echo "[INFO] Use filtlong: ${USE_FITLONG}"
echo

# ----------------------
# Per-sample processing
# ----------------------
for SAMPLE_DIR in "${INDIR}"/*; do
  [[ -d "${SAMPLE_DIR}" ]] || continue
  SAMPLE=$(basename "${SAMPLE_DIR}")
  echo "==========================================="
  echo "[START SAMPLE] ${SAMPLE}"
  echo "==========================================="

  SAMPLE_OUT="${OUTDIR}/${SAMPLE}"
  mkdir -p "${SAMPLE_OUT}"
  mkdir -p "${SAMPLE_OUT}/00.raw" "${SAMPLE_OUT}/01.qc" "${SAMPLE_OUT}/02.assembly" "${SAMPLE_OUT}/03.circlator" "${SAMPLE_OUT}/04.polish" "${SAMPLE_OUT}/05.annotation" "${SAMPLE_OUT}/06.mapping_qc"

  # gather fastq.gz files
  FASTQ_FILES=("${SAMPLE_DIR}"/*.fastq.gz)
  if [[ ${#FASTQ_FILES[@]} -eq 0 ]]; then
    echo "[WARN] No fastq.gz files found in ${SAMPLE_DIR}, skipping."
    continue
  fi

  # create merged raw fastq (uncompressed) to work with downstream tools
  RAW_MERGED="${SAMPLE_OUT}/00.raw/${SAMPLE}.raw.fastq"
  echo "[STEP] Merging raw fastq -> ${RAW_MERGED}"
  gunzip -c "${FASTQ_FILES[@]}" > "${RAW_MERGED}"

  # ----------------------
  # Step 1: NanoFilt (headcrop, length, quality)
  # ----------------------
  FILTERED="${SAMPLE_OUT}/01.qc/${SAMPLE}.filtered.fastq.gz"
  echo "[STEP] NanoFilt -> ${FILTERED}"
  gunzip -c "${RAW_MERGED}" \
    | NanoFilt --headcrop ${HEADCROP} -l ${MIN_LEN} -q ${MIN_Q} --verbose \
    | gzip > "${FILTERED}"

  CLEAN_FASTQ="${SAMPLE_OUT}/01.qc/${SAMPLE}.clean.fastq"
  gunzip -c "${FILTERED}" > "${CLEAN_FASTQ}"

  # optional: filtlong to keep best reads (helps if many short/low-quality)
  if [[ "${USE_FITLONG}" == true ]]; then
    echo "[STEP] filtlong (keep_percent=${FILTKEEPPCT}) -> ${SAMPLE_OUT}/01.qc/${SAMPLE}.filtlong.fastq"
    filtlong --min_length ${MIN_LEN} --keep_percent ${FILTKEEPPCT} "${CLEAN_FASTQ}" > "${SAMPLE_OUT}/01.qc/${SAMPLE}.filtlong.fastq"
    CLEAN_FASTQ="${SAMPLE_OUT}/01.qc/${SAMPLE}.filtlong.fastq"
  fi

  # ----------------------
  # Step 2: Flye assembly (plasmid-aware)
  # ----------------------
  echo "[STEP] Flye assembly (genome-size ${GENOME_SIZE})"
  flye --nano-raw "${CLEAN_FASTQ}" --out-dir "${SAMPLE_OUT}/02.assembly" --genome-size ${GENOME_SIZE} --threads ${THREADS} --plasmids

  ASM="${SAMPLE_OUT}/02.assembly/assembly.fasta"
  if [[ ! -f "${ASM}" ]]; then
    echo "[ERROR] Flye assembly failed for ${SAMPLE}"
    echo -e "${SAMPLE}\tNA\t0\t0\tflye\tflye_failed" >> "${SUMMARY}"
    continue
  fi

  # ----------------------
  # Step 3: Circlator circularization (if available)
  # ----------------------
  echo "[STEP] Circlator circularization"
  circlator all "${ASM}" "${CLEAN_FASTQ}" "${SAMPLE_OUT}/03.circlator" || {
    echo "[WARN] Circlator failed (nonfatal). Continuing with Flye assembly."
  }

  # Use circlator result if exists, else use flye assembly
  if [[ -f "${SAMPLE_OUT}/03.circlator/06.fixstart.fasta" ]]; then
    CIRCULAR="${SAMPLE_OUT}/03.circlator/06.fixstart.fasta"
    echo "[INFO] Using circlator output: ${CIRCULAR}"
  else
    CIRCULAR="${ASM}"
    echo "[INFO] Circlator output not found; using Flye assembly: ${CIRCULAR}"
  fi

  # ----------------------
  # Step 4: Racon polishing (iterative)
  # ----------------------
  POLISHED_RACON="${SAMPLE_OUT}/04.polish/racon_round0.fasta"
  cp "${CIRCULAR}" "${POLISHED_RACON}"

  for (( r=1; r<=RACON_ROUNDS; r++ )); do
    echo "[STEP] Racon round ${r}"
    aln="${SAMPLE_OUT}/04.polish/aln_round${r}.sam"
    minimap2 -ax map-ont "${POLISHED_RACON}" "${CLEAN_FASTQ}" > "${aln}"
    racon "${CLEAN_FASTQ}" "${aln}" "${POLISHED_RACON}" > "${SAMPLE_OUT}/04.polish/racon_round${r}.fasta"
    POLISHED_RACON="${SAMPLE_OUT}/04.polish/racon_round${r}.fasta"
    # cleanup intermediate sam to save space
    rm -f "${aln}"
  done

  # ----------------------
  # Step 5: Medaka consensus (final polishing)
  # ----------------------
  echo "[STEP] Medaka polishing"
  MEDAKA_OUTDIR="${SAMPLE_OUT}/04.polish/medaka"
  mkdir -p "${MEDAKA_OUTDIR}"
  medaka_consensus -i "${CLEAN_FASTQ}" -d "${POLISHED_RACON}" -o "${MEDAKA_OUTDIR}" -m "${MEDAKA_MODEL}"
  FINAL_FASTA="${MEDAKA_OUTDIR}/consensus.fasta"

  if [[ ! -f "${FINAL_FASTA}" ]]; then
    echo "[ERROR] Medaka failed to produce consensus for ${SAMPLE}"
    echo -e "${SAMPLE}\tNA\t0\t0\tmedaka_failed\tmedaka_failed" >> "${SUMMARY}"
    continue
  fi

  # ----------------------
  # Step 6: Prokka annotation
  # ----------------------
  echo "[STEP] Prokka annotation"
  prokka --outdir "${SAMPLE_OUT}/05.annotation" --prefix "${SAMPLE}" --cpus ${THREADS} "${FINAL_FASTA}" >/dev/null 2>&1 || {
    echo "[WARN] Prokka failed or had warnings; check logs."
  }

  # ----------------------
  # Step 7: Mapping QC (map reads back to final contigs)
  # ----------------------
  echo "[STEP] Mapping QC"
  MAPPED_BAM="${SAMPLE_OUT}/06.mapping_qc/${SAMPLE}.mapped.bam"
  minimap2 -ax map-ont "${FINAL_FASTA}" "${CLEAN_FASTQ}" | samtools sort -@ ${THREADS} -o "${MAPPED_BAM}"
  samtools index "${MAPPED_BAM}"
  samtools depth "${MAPPED_BAM}" > "${SAMPLE_OUT}/06.mapping_qc/depth.txt"

  # compute contig stats
  CONTIG_COUNT=$(grep -c "^>" "${FINAL_FASTA}" || echo 0)
  MAX_CONTIG_LEN=$(awk '/^>/ {if (seqlen){print seqlen}; seqlen=0; next} {seqlen+=length($0)} END{print seqlen}' "${FINAL_FASTA}" | sort -nr | head -n1 || echo 0)

  NOTES="ok"
  ASSEMBLY_METHOD="flye+polish"
  echo -e "${SAMPLE}\t${FINAL_FASTA}\t${CONTIG_COUNT}\t${MAX_CONTIG_LEN}\t${ASSEMBLY_METHOD}\t${NOTES}" >> "${SUMMARY}"

  echo "[DONE SAMPLE] ${SAMPLE}"
  echo
done

echo "[ALL DONE] Summary written to ${SUMMARY}"


â¸»

å…³äºè„šæœ¬çš„è‹¥å¹²è¯´æ˜ï¼ˆåŠ¡å¿…é˜…è¯»ï¼‰
	1.	å·¥å…·å®‰è£…ï¼šè„šæœ¬å‡å®š NanoFilt, filtlong (å¯é€‰), flye, circlator, minimap2, samtools, racon, medaka_consensus, prokka éƒ½å·²å®‰è£…ä¸”åœ¨ PATH ä¸­ã€‚è„šæœ¬åœ¨å¼€å¤´ä¼šæ£€æŸ¥å¿…éœ€å·¥å…·å¹¶æŠ¥é”™é€€å‡ºã€‚
	2.	Medaka æ¨¡å‹ï¼šè¯·æ ¹æ®ä½ çš„ flowcell / basecaller é€‰æ‹©åˆé€‚æ¨¡å‹ï¼ˆå¸¸è§ä¸º r1041_e82_260bps_sup æˆ– r941_min_high_g360 ç­‰ï¼‰ï¼Œè‹¥ä¸ç¡®å®šä¿æŒé»˜è®¤å¹¶æ£€æŸ¥ medaka æ–‡æ¡£ã€‚
	3.	Racon è½®æ•°ï¼šé»˜è®¤ 2 è½®ï¼›å¯æ”¹ä¸º 3 è½®ï¼Œä½†æ”¶ç›Šé€’å‡ã€‚
	4.	è¾“å…¥æ–‡ä»¶ï¼šæ¯ä¸ªæ ·å“å­ç›®å½•ä¸­å…è®¸æœ‰å¤šä¸ª fastq.gz æ–‡ä»¶ï¼ˆä¾‹å¦‚ split by runï¼‰ï¼Œè„šæœ¬ä¼šåˆå¹¶åä¸€èµ·å¤„ç†ã€‚
	5.	èµ„æºï¼šåœ¨ HPC/SLURM ä¸Šè¿è¡Œæ—¶å¯æŠŠè¿™è„šæœ¬ wrap æˆ sbatch ä½œä¸šï¼Œæˆ–æŠŠ per-sample å¾ªç¯æ”¹å†™ä¸ºå¹¶è¡Œ & æˆ– GNU parallelï¼ˆæ³¨æ„ IO å‹åŠ›ï¼‰ã€‚
	6.	å®¹é”™ï¼šflye æˆ– medaka å¤±è´¥ä¼šåœ¨ summary ä¸­å†™å…¥æ ‡è¯†å¹¶ç»§ç»­ä¸‹ä¸€ä¸ªæ ·å“ï¼ˆéƒ¨åˆ†æ­¥éª¤å¤±è´¥ä¼šè·³è¿‡åç»­æ­¥éª¤ï¼‰ã€‚
	7.	è¾“å‡ºï¼šæ¯ä¸ªæ ·å“çš„æœ€ç»ˆ consensus å­˜åœ¨ ${OUTDIR}/${SAMPLE}/04.polish/medaka/consensus.fastaï¼Œæ³¨é‡Šå­˜æ”¾åœ¨ 05.annotationï¼Œmapping depth åœ¨ 06.mapping_qc/depth.txtã€‚
	8.	å¯æ‰©å±•ï¼šå¦‚éœ€æ·»åŠ  medaka variant æ¥è°ƒç”¨SNP/indelã€Bandage å›¾å¯è§†åŒ–ã€æˆ–ç›´æ¥æ‰“åŒ…ä¸º Nextflow / Snakemake / Argoï¼Œæˆ‘å¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šç”Ÿæˆã€‚

â¸»

å¦‚æœä½ è¦æˆ‘åšä¸‹ä¸€æ­¥ï¼Œæˆ‘å¯ä»¥ç«‹åˆ»ï¼ˆåœ¨å½“å‰å“åº”ä¸­ï¼‰ï¼š
	â€¢	æŠŠè¿™ä¸ªè„šæœ¬æ”¹ä¸º SLURM sbatch ç‰ˆæœ¬ï¼ˆæ¯ä¸ªæ ·å“æäº¤ç‹¬ç«‹ä½œä¸šï¼‰ï¼Œæˆ–
	â€¢	æŠŠå®ƒè½¬æ¢ä¸º Nextflow / Snakemake workflowï¼ˆä¾¿äºå¯å¤ç°ä¸å¹¶è¡ŒåŒ–ï¼‰ï¼Œæˆ–
	â€¢	å¢åŠ  variant callingï¼ˆmedaka variantï¼‰ + summary reportï¼ˆåŒ…å«çªå˜åˆ—è¡¨ã€è¦†ç›–å›¾ï¼‰ï¼Œæˆ–
	â€¢	æ·»åŠ  è‡ªåŠ¨é‚®ä»¶é€šçŸ¥ / QC æŠ¥å‘Šï¼ˆHTMLï¼‰ã€‚

ä½ æƒ³å…ˆè¦å“ªä¸ªæ‰©å±•ï¼Ÿ
##########################################################################################################################################################################################################################################################################

##########################################################################################################################################################################################################################################################################

##########################################################################################################################################################################################################################################################################


å®Œæ•´å‡çº§ç‰ˆ split_plasmid_fasta.py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
split_plasmid_fasta.py
------------------------------------
Split plasmid FASTA sequences into fixed-length fragments.
Support specifying input/output/sample name through command-line arguments.

Usage:
    python split_plasmid_fasta.py --input INPUT.fasta --outdir OUTDIR [--sample SAMPLE] [--size 2000]

Example:
    python split_plasmid_fasta.py --input plasmid.fasta --outdir fragments --sample test01
"""

import os
import argparse
from Bio import SeqIO

DEFAULT_FRAGMENT_SIZE = 2000  # bp


def split_fasta(input_fasta, output_dir, sample_name=None, fragment_size=DEFAULT_FRAGMENT_SIZE):
    """Split each FASTA sequence into smaller fragments."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for record in SeqIO.parse(input_fasta, "fasta"):
        seq = record.seq
        seq_len = len(seq)

        for i in range(0, seq_len, fragment_size):
            fragment = seq[i:i + fragment_size]
            part_num = (i // fragment_size) + 1

            # output name supports sample name
            if sample_name:
                fragment_id = f"{sample_name}_{record.id}_part{part_num}"
            else:
                fragment_id = f"{record.id}_part{part_num}"

            output_path = os.path.join(output_dir, f"{fragment_id}.fasta")

            # Write fragment
            with open(output_path, "w") as out_f:
                out_f.write(">1.0\n")
                for j in range(0, len(fragment), 80):
                    out_f.write(str(fragment[j:j + 80]) + "\n")

            print(f"[OK] Wrote {output_path} ({len(fragment)} bp)")


def main():
    parser = argparse.ArgumentParser(description="Split plasmid FASTA into fixed-length fragments.")

    parser.add_argument("--input", "-i", required=True, help="Input FASTA file")
    parser.add_argument("--outdir", "-o", required=True, help="Output directory")
    parser.add_argument("--sample", "-s", default=None, help="Sample name prefix for output files")
    parser.add_argument("--size", "-l", type=int, default=DEFAULT_FRAGMENT_SIZE,
                        help="Fragment size (default: 2000 bp)")

    args = parser.parse_args()

    # Input validation
    if not os.path.isfile(args.input):
        raise FileNotFoundError(f"Input FASTA not found: {args.input}")

    split_fasta(
        input_fasta=args.input,
        output_dir=args.outdir,
        sample_name=args.sample,
        fragment_size=args.size,
    )


if __name__ == "__main__":
    main()

##########################################################################################################################################################################################################################################################################
#### 8. doushuang, plasmidçš„æŠ¥å‘Š
* 1. cursorè¾…åŠ©ç¼–å†™æ–°ç‰ˆçš„åˆ†ææŠ¥å‘Š;

```bash
results/final_test_PER_BASE_BREAKDOWN/
â”œâ”€â”€ UPA42701_UPA42701_per_base_details.csv âœ…
â”œâ”€â”€ UPA42701_UPA42701_low_confidence_bases.csv âœ…
â”œâ”€â”€ UPA42701_UPA42701_coverage.png âœ…
â””â”€â”€ UPA42701_read_length_dist.png âœ… (æ–°å¢)

results/final_test_QC_REPORTS/
â””â”€â”€ UPA42701_report.pdf âœ… (åŒ…å«read length distributionå›¾)
```
åˆæ­¥æµ‹è¯•é€šè¿‡,å¯ä»¥è¾“å‡ºæ­£ç¡®çš„åˆ†ææŠ¥å‘Šæ¨¡ç‰ˆ;

* 2. å‡çº§è„šæœ¬ç¨‹åº
æ˜¯å¦å¯ä»¥å¸®æˆ‘å†å‡çº§ä¸€ä¸‹, å¯ä»¥æŒ‡å®šæ ·å“,é¡¹ç›®å·, è¾“å…¥æ–‡ä»¶/ç›®å½•, æ­¤å¤–, å¸®æˆ‘åŸºäº/Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/QB-template ç›®å½•ä¸­çš„fastq,fastaæ–‡ä»¶, ç”Ÿæˆä¸€ä¸ªæµ‹è¯•æŠ¥å‘Š, 
æµ‹è¯•é€šè¿‡ä¹‹å, å†å‚è€ƒQB-template ä¸­çš„æ–‡ä»¶ç»„ç»‡æ–¹å¼, é’ˆå¯¹outoutä¸­çš„æ–‡ä»¶(å¤šä¸ªè´¨ç²’æ ·å“çš„æ•°æ®ç»“æœ), ç”Ÿæˆåˆ†åˆ«ç‹¬ç«‹çš„æŠ¥å‘Š, æ¯ä¸ªè´¨ç²’æ ·å“ä¸€ä¸ªç‹¬ç«‹çš„ç»“æœfolder, åŒ…å«å„ç§æ–‡ä»¶çš„å­folder(ab1æ–‡ä»¶å¤¹æš‚æ—¶ç©ºç€)

```bash
#å¤„ç†æ‰€æœ‰æ ·å“ï¼š
cd scripts
python3 generate_complete_reports.py -d ../output -o ../results --project-id final_reports
INFO: ============================================================
INFO: Organizing files by sample...
INFO:   Data directory: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/wf-clone-validation_3721d4d6-1e08-4db4-861c-f373b6934c07/output
INFO:   Output directory: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/wf-clone-validation_3721d4d6-1e08-4db4-861c-f373b6934c07/results
INFO:   Project ID: final_reports
INFO:   Found 14 samples
INFO: Processing 14 samples...
INFO: Processing sample: UPA42701
INFO:   Processing contig: UPA42701 (6814 bp)
INFO:     Computing coverage and per-base breakdown...
INFO: Mapped 1/1 reads to UPA42701
INFO:     âœ“ Coverage computed: avg=1.0x, mapped=1/1 reads
INFO:     Coverage plot already exists: UPA42701_UPA42701_coverage.png
INFO:   Counting reads and bases from FASTQ: UPA42701_reads.fastq
INFO:   âœ“ Total: 1 reads, 6,814 bases
INFO:   Calculating FASTA statistics...
INFO:   âœ“ Host Genomic DNA: 1 contigs, 6,814 bases
INFO:   Generating PDF report...
INFO:   âœ“ PDF report saved: UPA42701_report.pdf
INFO:   âœ“ Successfully processed UPA42701
...
...
...
INFO: Processing sample: USX265344
INFO:   Processing contig: USX265344 (7627 bp)
INFO:     Computing coverage and per-base breakdown...
INFO: Mapped 1/1 reads to USX265344
INFO:     âœ“ Coverage computed: avg=1.0x, mapped=1/1 reads
INFO:     Creating coverage plot...
INFO:     âœ“ Coverage plot saved: USX265344_USX265344_coverage.png
INFO:   Counting reads and bases from FASTQ: USX265344_reads.fastq
INFO:   âœ“ Total: 1 reads, 7,627 bases
INFO:   Calculating FASTA statistics...
INFO:   âœ“ Host Genomic DNA: 1 contigs, 7,627 bases
INFO:   Generating PDF report...
INFO:   âœ“ PDF report saved: USX265344_report.pdf
INFO:   âœ“ Successfully processed USX265344
INFO: Generating summary CSV...
INFO: Summary CSV written to: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/wf-clone-validation_3721d4d6-1e08-4db4-861c-f373b6934c07/results/final_reports_summary.csv
INFO: 
âœ“ Successfully processed 14 samples
INFO: Output structure: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/wf-clone-validation_3721d4d6-1e08-4db4-861c-f373b6934c07/results/{sample_name}/{subdirectories}
(base) liqinghui@LideMacBook-Pro scripts % 



#å¤„ç†æŒ‡å®šæ ·å“ï¼š
python3 generate_complete_reports.py -d ../output -o ../results --project-id final_reports --samples UPA42701 UPA42703

#ä½¿ç”¨QB-templateæ ¼å¼çš„è¾“å…¥ï¼š
python3 generate_complete_reports.py \
  --fasta-dir /path/to/FASTA_FILES \
  --fastq-dir /path/to/RAW_FASTQ_FILES \
  -o /path/to/output \
  --project-id project_name
```

* 4. æµ‹è¯•æ–°çš„å®Œæ•´è¾“å…¥,USX140904
```bash
(base) liqinghui@LideMacBook-Pro scripts % python3 generate_complete_reports.py -d ../../USX140904 -o ../USX140904 --project-id USX140904
INFO: ============================================================
INFO: Organizing files by sample...
INFO:   Data directory: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/USX140904
INFO:   Output directory: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/wf-clone-validation_3721d4d6-1e08-4db4-861c-f373b6934c07/USX140904
INFO:   Project ID: USX140904
INFO:   Found 1 samples
INFO: Processing 1 samples...
INFO: Processing sample: USX140904
WARNING: FASTQ file not found for USX140904
WARNING: Missing FASTQ file for USX140904
WARNING:   âš  No results generated for USX140904
INFO: 
âœ“ Successfully processed 0 samples
INFO: Output structure: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/wf-clone-validation_3721d4d6-1e08-4db4-861c-f373b6934c07/USX140904/{sample_name}/{subdirectories}
(base) liqinghui@LideMacBook-Pro scripts % 
(base) liqinghui@LideMacBook-Pro scripts % 
(base) liqinghui@LideMacBook-Pro scripts % 
(base) liqinghui@LideMacBook-Pro scripts % python3 generate_complete_reports.py -d ../../USX140904 -o ../USX140904 --project-id USX140904
INFO: ============================================================
INFO: Organizing files by sample...
INFO:   Data directory: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/USX140904
INFO:   Output directory: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/wf-clone-validation_3721d4d6-1e08-4db4-861c-f373b6934c07/USX140904
INFO:   Project ID: USX140904
INFO:   No exact match found, searching for files containing 'USX140904' in filename...
INFO:   Found FASTQ containing sample name: PBE94302_pass_USX140904_6ebb3c45_d6847234_0.fastq.gz
INFO:   Found 1 FASTQ file(s) for USX140904: ['PBE94302_pass_USX140904_6ebb3c45_d6847234_0.fastq.gz']
INFO:   Found 1 samples
INFO: Processing 1 samples...
INFO: Processing sample: USX140904
INFO:   Processing contig: USX140904 (4906 bp)
INFO:     Computing coverage and per-base breakdown...

INFO: Mapped 91/1279 reads to USX140904
INFO:     âœ“ Coverage computed: avg=29.1x, mapped=91/1,279 reads
INFO:     Creating coverage plot...
INFO:     âœ“ Coverage plot saved: USX140904_USX140904_coverage.png
INFO:   Counting reads and bases from FASTQ: USX140904_reads.fastq.gz
INFO:   âœ“ Total: 1,279 reads, 3,387,923 bases
INFO:   Calculating FASTA statistics...
INFO:   âœ“ Host Genomic DNA: 1 contigs, 4,906 bases
INFO:   Generating PDF report...
INFO:   âœ“ PDF report saved: USX140904_report.pdf
INFO:   âœ“ Successfully processed USX140904
INFO: Generating summary CSV...
INFO: Summary CSV written to: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/wf-clone-validation_3721d4d6-1e08-4db4-861c-f373b6934c07/USX140904/USX140904_summary.csv
INFO: 
âœ“ Successfully processed 1 samples
INFO: Output structure: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/wf-clone-validation_3721d4d6-1e08-4db4-861c-f373b6934c07/USX140904/{sample_name}/{subdirectories}
(base) liqinghui@LideMacBook-Pro scripts % 
```
![1c82cd7a78817d259a6a0c3fb4dffcd3.png](evernotecid://87E6BD0C-C63D-4350-BF05-363657F9594C/appyinxiangcom/2925421/ENResource/p12672)
```bash
1. è¦†ç›–åº¦å›¾ç”Ÿæˆè¿‡ç¨‹
å·²åˆ›å»ºæ–‡æ¡£ï¼šCOVERAGE_PLOT_GENERATION.mdï¼Œè¯´æ˜ç”Ÿæˆè¿‡ç¨‹ã€‚ç®€è¦æµç¨‹å¦‚ä¸‹ï¼š
ç”Ÿæˆæ­¥éª¤ï¼š
è®¡ç®—è¦†ç›–åº¦ (compute_coverage å‡½æ•°)
è¯»å– FASTA ä¸­çš„å‚è€ƒåºåˆ—ï¼ˆcontigï¼‰
ä» FASTQ è¯»å–æµ‹åº reads
ä½¿ç”¨ simple_align() å°†æ¯ä¸ª read æ¯”å¯¹åˆ°å‚è€ƒåºåˆ—
è®¡ç®—æ¯ä¸ªä½ç½®çš„è¦†ç›–æ·±åº¦ï¼ˆæ¯ä¸ªä½ç½®è¢«å¤šå°‘ reads è¦†ç›–ï¼‰
ç»Ÿè®¡ï¼šå¹³å‡è¦†ç›–åº¦ã€æœ€å¤§è¦†ç›–åº¦ã€æ¯”å¯¹æˆåŠŸçš„ reads æ•°é‡
ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ (create_coverage_plot å‡½æ•°)
ä½¿ç”¨ matplotlib ç»˜åˆ¶æŠ˜çº¿å›¾ï¼ˆè“è‰²çº¿æ¡ + æµ…è“è‰²å¡«å……åŒºåŸŸï¼‰
æ ‡è®°ä½ç½®ä¿¡åº¦åŒºåŸŸï¼ˆè¦†ç›–åº¦ < 3x çš„ä½ç½®ï¼Œç”¨æ©™è‰² 'x' æ ‡è®°ï¼‰
æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ¡†ï¼ˆå¹³å‡å’Œæœ€å¤§è¦†ç›–åº¦ï¼‰
ä¿å­˜ä¸º PNG æ–‡ä»¶

å›¾è¡¨ç‰¹å¾ï¼š
Xè½´ï¼šåŸºå› ç»„ä½ç½®ï¼ˆbpï¼‰
Yè½´ï¼šè¦†ç›–æ·±åº¦ï¼ˆxï¼‰
è“è‰²çº¿æ¡ï¼šè¦†ç›–åº¦æ›²çº¿
æ©™è‰² 'x'ï¼šä½ç½®ä¿¡åº¦åŒºåŸŸæ ‡è®°
ç»Ÿè®¡æ¡†ï¼šæ˜¾ç¤ºå¹³å‡å’Œæœ€å¤§è¦†ç›–åº¦
2. Assembly Status è¡¨æ ¼ç™¾åˆ†æ¯”æ˜¾ç¤º
å·²åœ¨ Assembly Status è¡¨æ ¼çš„ Reads Mapped å’Œ Bases Mapped åˆ—æ·»åŠ ç™¾åˆ†æ¯”ï¼š
ä¿®æ”¹åçš„æ˜¾ç¤ºæ ¼å¼ï¼š
Reads Mapped: 8,500 (85.00%)
Bases Mapped: 4,250,000 (85.00%)
ç™¾åˆ†æ¯”è®¡ç®—æ–¹å¼ï¼š
Reads Mapped % = (æ¯”å¯¹æˆåŠŸçš„readsæ•° / FASTQä¸­çš„æ€»readsæ•°) Ã— 100
Bases Mapped % = (æ¯”å¯¹æˆåŠŸçš„basesæ•° / FASTQä¸­çš„æ€»basesæ•°) Ã— 100

```

* 5. å®Œæ•´çš„æµç¨‹pipelineè¯´æ˜æ–‡æ¡£;
```bash
README_EN.md å®Œæˆæƒ…å†µ
æ–‡æ¡£å·²å°±ç»ªï¼Œå…± 681 è¡Œï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
ä¸»è¦ç« èŠ‚
Features - æ ¸å¿ƒåŠŸèƒ½ä¸é«˜çº§åŠŸèƒ½
Installation - å®‰è£…è¯´æ˜ï¼ˆä¾èµ–ã€ç³»ç»Ÿè¦æ±‚ï¼‰
Project Structure - é¡¹ç›®ç›®å½•ç»“æ„
Usage - åŸºæœ¬ç”¨æ³•ä¸å¸¸è§ç”¨ä¾‹
Output Structure - è¾“å‡ºç›®å½•ç»“æ„è¯´æ˜
Report Contents - PDFæŠ¥å‘Šå†…å®¹è¯¦è§£
Command-Line Options - æ‰€æœ‰å‘½ä»¤è¡Œå‚æ•°è¯¦è§£
Examples - 6ä¸ªä½¿ç”¨ç¤ºä¾‹
Troubleshooting - 6ä¸ªå¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ
FAQs - 10ä¸ªå¸¸è§é—®é¢˜è§£ç­”
Technical Details - æŠ€æœ¯ç»†èŠ‚ï¼ˆè¦†ç›–åº¦è®¡ç®—ã€readé•¿åº¦åˆ†å¸ƒç­‰ï¼‰
Additional Resources - ç›¸å…³èµ„æºé“¾æ¥
Support - æ”¯æŒä¿¡æ¯
Version History - ç‰ˆæœ¬å†å²
æ–‡æ¡£ç‰¹ç‚¹
```



##########################################################################################################################################################################################################################################################################

#### 1. doushuangçš„nanoporeæµ‹è´¨ç²’çš„åˆ†ææŠ¥å‘Šå¤„ç†
* 1. æ ·å“åºåˆ—é•¿åº¦åˆ†å¸ƒ;
å®Œæˆäº¤ä»˜ç»™doushuang

* 2. å°†epi2meçš„å¤šä¸ªè´¨ç²’åˆå¹¶çš„å•ä¸ªhtmlæŠ¥å‘Š, åˆ†å‰²æˆç‹¬ç«‹çš„å•ä¸€sampleè´¨ç²’çš„htmlåŠ¨æ€æŠ¥å‘Š.
å®Œæˆ;
>è„šæœ¬: /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/scripts/extract_sample_reports_epi2me.py


* 2. å‚è€ƒquintara bioçš„pdfæŠ¥å‘Š, å‡ºä¸€ä¸ªç®€ç‰ˆçš„æ ¸å¿ƒæŠ¥å‘Š



##########################################################################################################################################################################################################################################################################

#### 3. doushuang,æ•°æ®åˆ†æå’Œæ•´ç†
* 1. æ•´ç†éœ€æ±‚å’Œæ•°æ®
doushuang:
/upload/Plasmid/output/fasta
è¿™é‡Œæœ‰17ä¸ªfastaæ–‡ä»¶ã€‚
è´¨ç²’å¤§å°ä»3000-7000å¤šéƒ½æœ‰ã€‚
éº»çƒ¦ä½ å¸®æˆ‘æŠŠä»–ä»¬å˜æˆ17ä¸ªab1æ–‡ä»¶

```bash
(base) bioinfo@ampseq01:/data2/projects$ mkdir nanopore_20251031
(base) bioinfo@ampseq01:/data2/projects$ cd nanopore_20251031
(base) bioinfo@ampseq01:/data2/projects/nanopore_20251031$ 
sftp -P 30025 ct_ampseq@192.168.168.48 [uvSHkvxk]
```


* 2. è¿è¡Œåˆ†æ
1ï¸âƒ£ Plasmid fasta â†’ åˆ†å‰²ä¸º 2kb ç‰‡æ®µ
2ï¸âƒ£ 2kb ç‰‡æ®µ â†’ HyraxAbif ç”Ÿæˆ ab1 æ–‡ä»¶
3ï¸âƒ£ å¯¹åº” fastq.gz â†’ è·å–é•¿åº¦åˆ†å¸ƒ

```bash
#local
scp  -P 3035  /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/scripts/get_length_dist_from_fastq.py qinghui@50.186.231.9:/mnt/data4/argo-argo-workspace-pvc-data4/liqh/
scp  -P 3035  /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/scripts/split_plasmid_fasta.py qinghui@50.186.231.9:/mnt/data4/argo-argo-workspace-pvc-data4/liqh/

#ampseq01:
(base) bioinfo@ampseq01:/data2/projects/nanopore_20251031$ sudo cp /data4/liqh/get_length_dist_from_fastq.py /opt/scripts/
(base) bioinfo@ampseq01:/data2/projects/nanopore_20251031$ chmod 777 /opt/scripts/
(base) bioinfo@ampseq01:/data2/projects/nanopore_20251031$ sudo cp /data4/liqh/split_plasmid_fasta.py  /opt/scripts/
```

```bash
(base) bioinfo@ampseq01:/data2/projects/nanopore_20251031$ ll /data2/projects/nanopore_20251031/Plasmid/output/fasta/*fasta|awk '{print $9}'
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U0586NNEG0-10-UPA42701.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U0586NNEG0-10-UPA42742.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U0586NNEG0-12-UPA42703.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U0586NNEG0-8-UPA42705.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U0586NNEG0-9-UPA42747.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U1031KAGG0-17-USX187559A.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U1031KAGG0-5-USX187552A.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U166P789G0-4-USX217573.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U2262YNJG0-50-USX214545.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U404ESJJG0-12-USX166936B.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U7227VYZG0-20-USX265318.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U7227VYZG0-32-USX265335.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U7227VYZG0-80-USX265344.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U784LPYHG0-21-USX227568A.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U8600HSUG0-6AK-USX140903.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U8600HSUG0-6AK-USX140904.fasta
/data2/projects/nanopore_20251031/Plasmid/output/fasta/U8600HSUG0-6A-USX140562.fasta
(base) bioinfo@ampseq01:/data2/projects/nanopore_20251031$ 


python /opt/scripts/split_plasmid_fasta.py plasmid.fasta demo_data
/data1/opt/hyraxAbif/hyraxAbif-exe gen demo_data demo_data_ab1_results
```

ğŸ§© æ•´åˆè„šæœ¬ï¼šrun_plasmid_pipeline.sh
```bash
#!/bin/bash
# ===========================================
# Plasmid pipeline for Nanopore 20251031 project
# Author: Qinghui
# Date: 2025-10-31
# ===========================================

set -euo pipefail

# ---- user settings ----
FASTA_DIR="/data2/projects/nanopore_20251031/Plasmid/output/fasta"
FASTQ_DIR="/data2/projects/nanopore_20251031/Plasmid/fast_pass"
RESULTS_DIR="/data2/projects/nanopore_20251031/Plasmid/results"

SPLIT_SCRIPT="/opt/scripts/split_plasmid_fasta.py"
LEN_SCRIPT="/opt/scripts/get_length_dist_from_fastq.py"
HYRAX_EXE="/data1/opt/hyraxAbif/hyraxAbif-exe"

mkdir -p "${RESULTS_DIR}"

echo "[INFO] Starting plasmid processing pipeline..."
echo "[INFO] FASTA directory: ${FASTA_DIR}"
echo "[INFO] FASTQ directory: ${FASTQ_DIR}"
echo "[INFO] Results directory: ${RESULTS_DIR}"

# loop all the fasta files
for fasta_file in ${FASTA_DIR}/*.fasta; do
    plasmid_name=$(basename "${fasta_file}" .fasta)
    echo "-----------------------------------------------"
    echo "[INFO] Processing plasmid: ${plasmid_name}"

    # make result folder for current plasmid
    OUTDIR="${RESULTS_DIR}/${plasmid_name}"
    mkdir -p "${OUTDIR}"

    # Step 1: split fasta into 2kb fragments
    echo "[STEP 1] Splitting FASTA into 2kb fragments..."
    SPLIT_OUT="${OUTDIR}/2kb_fragments"
    mkdir -p "${SPLIT_OUT}"
    python "${SPLIT_SCRIPT}" "${fasta_file}" "${SPLIT_OUT}"

    # Step 2: generate ab1 results
    echo "[STEP 2] Generating AB1 files with hyraxAbif..."
    AB1_OUT="${OUTDIR}/2kb_fragments_ab1_results"
    mkdir -p "${AB1_OUT}"
    "${HYRAX_EXE}" gen "${SPLIT_OUT}" "${AB1_OUT}"

    # Step 3: get fastq files and generate length distribution
    echo "[STEP 3] Generating read length distribution..."
    # fetch sample id from fasta namesï¼ˆsuch as USXxxxxxx or UPAxxxxxxï¼‰
    sample_tag=$(echo "${plasmid_name}" | grep -oE '(USX[0-9A-Za-z]+|UPA[0-9A-Za-z]+)')
    fastq_file=$(find "${FASTQ_DIR}" -type f -name "*${sample_tag}*.fastq.gz" | head -n 1 || true)

    if [[ -n "${fastq_file}" && -f "${fastq_file}" ]]; then
        echo "[INFO] Found matching fastq: ${fastq_file}"
        python "${LEN_SCRIPT}" "${fastq_file}" --output-dir "${OUTDIR}"
    else
        echo "[WARN] No matching fastq found for ${plasmid_name}"
    fi

    echo "[DONE] Completed ${plasmid_name}"
done

echo "==============================================="
echo "[ALL DONE] Results saved in ${RESULTS_DIR}"
```
æ‰§è¡Œå®Œåï¼Œç›®å½•ç»“æ„å°†å¦‚ä¸‹ï¼š
```text
/data2/projects/nanopore_20251031/Plasmid/results/
â”œâ”€â”€ U0586NNEG0-10-UPA42701/
â”‚   â”œâ”€â”€ demo_data/                        # 2kbåˆ†å‰²ç»“æœ
â”‚   â”œâ”€â”€ demo_data_ab1_results/            # ab1æ¨¡æ‹Ÿç»“æœ
â”‚   â”œâ”€â”€ PBE94302_pass_UPA42701_length_dist.txt (ç¤ºä¾‹)
â”‚   â””â”€â”€ length_distribution_plot.png
â”œâ”€â”€ U0586NNEG0-12-UPA42703/
â”‚   â”œâ”€â”€ demo_data/
â”‚   â”œâ”€â”€ demo_data_ab1_results/
â”‚   â”œâ”€â”€ ...
â””â”€â”€ ...
```

ä½¿ç”¨æ–¹æ³•
```bash
cd /data2/projects/nanopore_20251031
bash run_plasmid_pipeline.sh
```


é‡åˆ°stacké—®é¢˜:
```bash
(base) bioinfo@ampseq01:/opt/hyraxAbif$ STACK_YAML="stack.yaml" stack build hyraxAbif --no-run-tests --allow-different-user 

(base) bioinfo@ampseq01:/opt/hyraxAbif$  stack exec hyraxAbif-exe dump --help
Usage: stack exec COMMAND 
                  [-- ARGUMENT(S) (e.g. stack exec ghc-pkg -- describe base)] 
                  [--[no-]ghc-package-path] [--[no-]stack-exe] 
                  [--package PACKAGE] [--rts-options RTSFLAG] [--cwd DIR] 
                  [--setup-info-yaml URL] [--snapshot-location-base URL] 
                  [--help]

  Execute a command. If the command is absent, the first of any arguments is
  taken as the command.

Available options:
  --[no-]ghc-package-path  Enable/disable setting the GHC_PACKAGE_PATH variable
                           for the subprocess (default: enabled)
  --[no-]stack-exe         Enable/disable setting the STACK_EXE environment
                           variable to the path for the stack executable
                           (default: enabled)
  --package PACKAGE        Add a package (can be specified multiple times)
  --rts-options RTSFLAG    Explicit RTS options to pass to application
  --cwd DIR                Sets the working directory before executing
  --setup-info-yaml URL    Alternate URL or relative / absolute path for Stack
                           dependencies
  --snapshot-location-base URL
                           The base location of LTS/Nightly snapshots
  --help                   Show this help text

Command 'stack --help' for global options that apply to all subcommands.
(base) bioinfo@ampseq01:/opt/hyraxAbif$ 


#(base) bioinfo@ampseq01:/data2/projects/nanopore_20251031$ 
/data1/opt/hyraxAbif/hyraxAbif-exe gen Plasmid/results/U0586NNEG0-10-UPA42701/2kb_fragments Plasmid/results/U0586NNEG0-10-UPA42701/2kb_fragments_ab1_results


/data1/opt/hyraxAbif/hyraxAbif-exe --allow-different-user gen 2kb_fragments 2kb_fragments_ab1


(base) bioinfo@ampseq01:/data2/projects/nanopore_20251031$ export STACK_IN_CONTAINER=1
export TMPDIR=/data2/tmp_hyrax
unset STACK_YAML
sudo /data1/opt/hyraxAbif/hyraxAbif-exe gen \
  Plasmid/results/U0586NNEG0-10-UPA42701/2kb_fragments \
  Plasmid/results/U0586NNEG0-10-UPA42701/2kb_fragments_ab1_results
Writing implicit global project config file to: /tmp/global-project/stack.yaml
Note: You can change the snapshot via the resolver field there.
HttpExceptionRequest Request {
  host                 = "s3.amazonaws.com"
  port                 = 443
  secure               = True
  requestHeaders       = [("Accept","application/json"),("User-Agent","The Haskell Stack")]
  path                 = "/haddock.stackage.org/snapshots.json"
  queryString          = ""
  method               = "GET"
  proxy                = Nothing
  rawBody              = False
  redirectCount        = 10
  responseTimeout      = ResponseTimeoutDefault
  requestVersion       = HTTP/1.1
  proxySecureMode      = ProxySecureWithConnect
}
 (StatusCodeException (Response {responseStatus = Status {statusCode = 403, statusMessage = "Forbidden"}, responseVersion = HTTP/1.1, responseHeaders = [("x-amz-request-id","J5HW8WZSVSRRNJAJ"),("x-amz-id-2","xpEQHBu8UXEGxAz4HqlmL5+LKRAOl2wt02VVy9SdzEH8ei6ccBifD7Egm93KVfuf2Y0RrkzlQH7Wouc/Lec7aPJBljLDWOW0"),("Content-Type","application/xml"),("Transfer-Encoding","chunked"),("Date","Fri, 31 Oct 2025 10:31:06 GMT"),("Server","AmazonS3")], responseBody = (), responseCookieJar = CJ {expose = []}, responseClose' = ResponseClose, responseOriginalRequest = Request {
  host                 = "s3.amazonaws.com"
  port                 = 443
  secure               = True
  requestHeaders       = [("Accept","application/json"),("User-Agent","The Haskell Stack")]
  path                 = "/haddock.stackage.org/snapshots.json"
  queryString          = ""
  method               = "GET"
  proxy                = Nothing
  rawBody              = False
  redirectCount        = 10
  responseTimeout      = ResponseTimeoutDefault
  requestVersion       = HTTP/1.1
  proxySecureMode      = ProxySecureWithConnect
}
}) "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>J5HW8WZSVSRRNJAJ</RequestId><HostId>xpEQHBu8UXEGxAz4HqlmL5+LKRAOl2wt02VVy9SdzEH8ei6ccBifD7Egm93KVfuf2Y0RrkzlQH7Wouc/Lec7aPJBljLDWOW0</HostId></Error>")
(base) bioinfo@ampseq01:/data2/projects/nanopore_20251031$ 

```

é‡æ–°ç¼–è¯‘:
(base) bioinfo@ampseq01:/opt/hyraxAbif$ STACK_YAML="stack.yaml" stack build hyraxAbif --no-run-tests --allow-different-user 
Getting project config file from STACK_YAML environment
(base) bioinfo@ampseq01:/opt/hyraxAbif$ stack exec hyraxAbif-exe dump --help
Usage: stack exec COMMAND 
                  [-- ARGUMENT(S) (e.g. stack exec ghc-pkg -- describe base)] 
                  [--[no-]ghc-package-path] [--[no-]stack-exe] 
                  [--package PACKAGE] [--rts-options RTSFLAG] [--cwd DIR] 
                  [--setup-info-yaml URL] [--snapshot-location-base URL] 
                  [--help]

  Execute a command. If the command is absent, the first of any arguments is
  taken as the command.

Available options:
  --[no-]ghc-package-path  Enable/disable setting the GHC_PACKAGE_PATH variable
                           for the subprocess (default: enabled)
  --[no-]stack-exe         Enable/disable setting the STACK_EXE environment
                           variable to the path for the stack executable
                           (default: enabled)
  --package PACKAGE        Add a package (can be specified multiple times)
  --rts-options RTSFLAG    Explicit RTS options to pass to application
  --cwd DIR                Sets the working directory before executing
  --setup-info-yaml URL    Alternate URL or relative / absolute path for Stack
                           dependencies
  --snapshot-location-base URL
                           The base location of LTS/Nightly snapshots
  --help                   Show this help text

Command 'stack --help' for global options that apply to all subcommands.
(base) bioinfo@ampseq01:/opt/hyraxAbif$ 

#å–æ¶ˆSTACK_YAMLè®¾ç½®:
(base) bioinfo@ampseq01:/opt/hyraxAbif$ unset STACK_YAML

#æˆåŠŸè¿è¡Œ(æ³¨æ„éœ€è¦åœ¨è½¯ä»¶å®‰è£…ç›®å½•ä¸‹è¿è¡Œ):
(base) bioinfo@ampseq01:/opt/hyraxAbif$ /data1/opt/hyraxAbif/hyraxAbif-exe gen demo_data demo_data_ab1_results

å‡çº§é•¿åº¦åˆ†å¸ƒè„šæœ¬, æœ€ç»ˆç»“æœè¾“å‡ºåˆ°resultsç›®å½•:
(base) bioinfo@ampseq01:/data2/projects/nanopore_20251031/Plasmid$ ll
total 28
drwxr-xr-x  7 bioinfo bioinfo 4096 Oct 31 10:14 ./
drwxrwxr-x  3 bioinfo bioinfo 4096 Oct 31 10:43 ../
drwxr-xr-x 19 bioinfo bioinfo 4096 Oct 31 09:53 fast_pass/
drwxr-xr-x  5 bioinfo bioinfo 4096 Oct 31 09:53 Lei-template/
drwxr-xr-x  8 bioinfo bioinfo 4096 Oct 31 09:53 output/
drwxr-xr-x  8 bioinfo bioinfo 4096 Oct 31 09:53 QB-template/
drwxrwxr-x 19 bioinfo bioinfo 4096 Oct 31 10:44 results/
'
##########################################################################################################################################################################################################################################################################
#### 1. doushuangçš„å…³äº.abæ–‡ä»¶è¾“å‡ºå›¾ç‰‡
æ¨¡æ‹Ÿä¸€ä»£æµ‹åºçš„ä¿¡å·å›¾;
```bash
https://github.com/hyraxbio/hyraxAbif?tab=readme-ov-file
cd /opt/
git clone https://github.com/hyraxbio/hyraxAbif.git
cd /opt/hyraxAbif
#(base) bioinfo@ampseq01:/opt/hyraxAbif
sudo apt-get install haskell-stack
make build
æŠ¥é”™,åœ¨stack.yaml fileä¸­æ·»åŠ é¢å¤–2è¡Œ
extra-deps:
  - stm-2.5.3.1@sha256:421b57c9cdf55b4977e9445336be3895ba0c8d92b6ec6e474f140e173270d9dd,2443
  - verset-0.0.1.11

#å†æ‰§è¡Œæ›´æ–°:
stack update
stack build

#å†ç¼–è¯‘:
(base) bioinfo@ampseq01:/opt/hyraxAbif$ make build
STACK_YAML="stack.yaml" stack build hyraxAbif --no-run-tests
Getting project config file from STACK_YAML environment

#å®‰è£…æˆåŠŸ:
stack exec hyraxAbif-exe dump --help

Usage: stack exec COMMAND 
                  [-- ARGUMENT(S) (e.g. stack exec ghc-pkg -- describe base)] 
                  [--[no-]ghc-package-path] [--[no-]stack-exe] 
                  [--package PACKAGE] [--rts-options RTSFLAG] [--cwd DIR] 
                  [--setup-info-yaml URL] [--snapshot-location-base URL] 
                  [--help]

  Execute a command. If the command is absent, the first of any arguments is
  taken as the command.

Available options:
  --[no-]ghc-package-path  Enable/disable setting the GHC_PACKAGE_PATH variable
                           for the subprocess (default: enabled)
  --[no-]stack-exe         Enable/disable setting the STACK_EXE environment
                           variable to the path for the stack executable
                           (default: enabled)
  --package PACKAGE        Add a package (can be specified multiple times)
  --rts-options RTSFLAG    Explicit RTS options to pass to application
  --cwd DIR                Sets the working directory before executing
  --setup-info-yaml URL    Alternate URL or relative / absolute path for Stack
                           dependencies
  --snapshot-location-base URL
                           The base location of LTS/Nightly snapshots
  --help                   Show this help text

Command 'stack --help' for global options that apply to all subcommands.

```bash
(base) bioinfo@ampseq01:/opt/hyraxAbif/demo_data$ cat > demo1.fasta
> 0.5
ACG
> 0.3
AAAA
> 1
__AC
^C
(base) bioinfo@ampseq01:/opt/hyraxAbif/demo_data$ more demo1.fasta 
> 0.5
ACG
> 0.3
AAAA
> 1
__AC


(base) bioinfo@ampseq01:/opt/hyraxAbif/demo_data$ ../hyraxAbif-exe gen demo1.fasta demo_results
hyraxAbif-exe: demo1.fasta: getDirectoryContents:openDirStream: inappropriate type (Not a directory)
(base) bioinfo@ampseq01:/opt/hyraxAbif/demo_data$ cd ..
(base) bioinfo@ampseq01:/opt/hyraxAbif$ ./hyraxAbif-exe gen demo_data demo_data
(base) bioinfo@ampseq01:/opt/hyraxAbif$ ll demo_data/
total 20
drwxrwxr-x  3 bioinfo bioinfo 4096 Oct 23 01:00 ./
drwxrwxr-x 10 bioinfo bioinfo 4096 Oct 23 00:58 ../
-rw-rw-r--  1 bioinfo bioinfo  916 Oct 23 01:00 demo1.ab1
-rw-rw-r--  1 bioinfo bioinfo   30 Oct 23 00:58 demo1.fasta
drwxrwxr-x  2 bioinfo bioinfo 4096 Oct 23 00:59 demo_results/
(base) bioinfo@ampseq01:/opt/hyraxAbif$ 

#ç”Ÿæˆäº†demo1.ab1æ–‡ä»¶;

hyraxAbif-exe dump demo_data/demo1.ab1
#ä¼šè¾“å‡ºè¯¦ç»†ä¿¡æ¯;
```


./hyraxAbif-exe gen demo_data demo_data
å†ç”¨ApEè½¯ä»¶å¯è§†åŒ–:
![5eb53ecb114da9183a3c3a654e30f1e3.png](evernotecid://87E6BD0C-C63D-4350-BF05-363657F9594C/appyinxiangcom/2925421/ENResource/p12656)

##########################################################################################################################################################################################################################################################################


å¥½ â€” æˆ‘ä¼šç«‹åˆ»æŠŠ Pipeline 2.0ï¼ˆåŸºäºæœ€æ–°ç‰ˆ wf-clone-validationï¼‰ çš„å…¨éƒ¨å¿…è¦æ–‡ä»¶ä¸€æ¬¡æ€§ç»™å‡ºï¼š
	â€¢	Dockerfileï¼ˆv2.0ï¼Œå¯æ„å»ºé•œåƒï¼‰
	â€¢	entrypoint.shï¼ˆå®¹å™¨å…¥å£ï¼Œä¸€é”®è·‘å…¨æµç¨‹ï¼‰
	â€¢	generate_samplesheet.pyï¼ˆä» fast_pass/ è‡ªåŠ¨ç”Ÿæˆ samplesheet.csvï¼‰
	â€¢	split_plasmid_fasta_v2.pyï¼ˆå‡çº§ç‰ˆåˆ†ç‰‡è„šæœ¬ï¼Œå¯æŒ‡å®š sample/project ç­‰ï¼‰
	â€¢	generate_complete_reports_v3.pyï¼ˆå‡çº§ç‰ˆæŠ¥å‘Šç”Ÿæˆå™¨ï¼Œæ”¯æŒ epi2me è¾“å‡ºä¸ fasta/fastq æ¨¡å¼ï¼‰

æˆ‘ä¹Ÿä¼šåœ¨æœ«å°¾ç»™å‡ºæ„å»ºä¸è¿è¡Œè¯´æ˜ã€å¸¸è§é—®é¢˜å¤„ç†æç¤ºï¼ˆä¾‹å¦‚ hyraxAbif ç¼–è¯‘/Stack é—®é¢˜ã€Nextflow profiles é€‰æ‹©ï¼‰ï¼Œä»¥åŠç¤ºä¾‹å‘½ä»¤ï¼Œæ–¹ä¾¿ä½ ç›´æ¥æŠŠè¿™äº›æ–‡ä»¶æ”¾åˆ°é¡¹ç›®ç›®å½•æ„å»ºå¹¶è¿è¡Œã€‚

â¸»

æç¤ºï¼šé•œåƒé‡ŒåŒ…å« nextflow, minimap2, samtools, python3ï¼ˆå« Biopython/pandas/matplotlib/reportlabï¼‰ä»¥åŠ hyraxAbif çš„æºç å¹¶å°è¯•ç¼–è¯‘ï¼ˆéœ€è¦è”ç½‘ï¼‰ã€‚å¦‚æœä½ å¸Œæœ›è·³è¿‡ç¼–è¯‘è€ŒæŒ‚è½½å·²ç¼–è¯‘çš„ hyraxAbif-exeï¼Œæˆ‘åœ¨è¯´æ˜ä¸­ä¹Ÿä¼šæ ‡å‡ºå¦‚ä½•åšã€‚

â¸»

1) Dockerfile (plasmid-pipeline:2.0)

æŠŠä¸‹é¢ä¿å­˜ä¸º Dockerfileï¼ˆåŒç›®å½•æ”¾å…¥ split_plasmid_fasta_v2.pyã€generate_samplesheet.pyã€generate_complete_reports_v3.pyã€entrypoint.shï¼Œä»¥ä¾¿ COPYï¼‰ï¼š

# Dockerfile for Plasmid Pipeline v2.0
# Includes: nextflow, wf-clone-validation (downloaded at runtime), minimap2, samtools,
# Python env (biopython/pandas/matplotlib/reportlab), and hyraxAbif (source, will be built if network available).
FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive
ENV LANG=C.UTF-8 LC_ALL=C.UTF-8

# -------------------------
# system packages
# -------------------------
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl wget git ca-certificates build-essential unzip bzip2 \
    python3 python3-pip python3-venv python3-dev \
    default-jdk-headless openjdk-17-jre-headless \
    gcc g++ make pkg-config \
    zlib1g-dev libbz2-dev liblzma-dev libcurl4-openssl-dev \
    gnupg squashfs-tools apt-transport-https \
    && rm -rf /var/lib/apt/lists/*

# -------------------------
# Install miniconda (mamba) for bio conda packages
# -------------------------
ENV CONDA_DIR=/opt/conda
RUN wget -qO /tmp/miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && \
    bash /tmp/miniconda.sh -b -p ${CONDA_DIR} && \
    rm /tmp/miniconda.sh
ENV PATH=${CONDA_DIR}/bin:${PATH}

# create a small conda env and install bio tools with mamba
RUN conda install -y -c conda-forge mamba && \
    mamba install -y -c bioconda minimap2 samtools flye bwa seqtk && \
    mamba install -y -c conda-forge openjdk && \
    mamba clean -y --all

# -------------------------
# Install Nextflow
# -------------------------
RUN curl -s https://get.nextflow.io | bash && mv nextflow /usr/local/bin/ && chmod +x /usr/local/bin/nextflow

# -------------------------
# Python deps
# -------------------------
RUN python3 -m pip install --no-cache-dir biopython pandas numpy matplotlib reportlab seaborn

# -------------------------
# Haskell stack for hyraxAbif build (optional)
# -------------------------
RUN apt-get update && apt-get install -y --no-install-recommends haskell-stack ca-certificates && rm -rf /var/lib/apt/lists/*

# -------------------------
# Create directories and copy scripts
# -------------------------
WORKDIR /opt/pipeline
COPY split_plasmid_fasta_v2.py /opt/pipeline/split_plasmid_fasta_v2.py
COPY generate_samplesheet.py /opt/pipeline/generate_samplesheet.py
COPY generate_complete_reports_v3.py /opt/pipeline/generate_complete_reports_v3.py
COPY entrypoint.sh /opt/pipeline/entrypoint.sh
RUN chmod +x /opt/pipeline/entrypoint.sh /opt/pipeline/split_plasmid_fasta_v2.py /opt/pipeline/generate_samplesheet.py /opt/pipeline/generate_complete_reports_v3.py

# -------------------------
# hyraxAbif: clone source (build during image build if network available)
# -------------------------
WORKDIR /opt
RUN git clone https://github.com/hyraxbio/hyraxAbif.git || true
WORKDIR /opt/hyraxAbif

# Create safe TMP for stack build to avoid permission check problems
ENV TMPDIR=/opt/.stack-tmp
RUN mkdir -p ${TMPDIR} && chmod 777 ${TMPDIR}

# If network available, attempt to build hyraxAbif; failure won't abort final image build
RUN if [ -d /opt/hyraxAbif ]; then \
      echo "Attempting stack update/build for hyraxAbif (may require network)"; \
      STACK_YAML=stack.yaml stack update || echo "stack update failed"; \
      STACK_YAML=stack.yaml stack build hyraxAbif --no-run-tests || echo "stack build failed"; \
      make -C /opt/hyraxAbif build || echo "make build failed"; \
    fi || true

# -------------------------
# final
# -------------------------
WORKDIR /data
ENV PATH=/opt/conda/bin:/usr/local/bin:${PATH}

# entrypoint
ENTRYPOINT ["/opt/pipeline/entrypoint.sh"]
CMD ["--help"]

è¯´æ˜ä¸æ³¨æ„äº‹é¡¹ï¼š
	â€¢	é•œåƒå°è¯• clone & build hyraxAbifï¼Œä½†æ„å»ºä¾èµ–å¤–ç½‘ï¼ˆHackage/S3ï¼‰ã€‚è‹¥ç¯å¢ƒä¸å…è®¸è”ç½‘ï¼Œé•œåƒæ„å»ºä¼šè·³è¿‡ç¼–è¯‘ï¼ˆé•œåƒä»èƒ½ä½¿ç”¨å…¶å®ƒåŠŸèƒ½ï¼‰ï¼Œä½ å¯ä»¥æŠŠå·²ç»ç¼–è¯‘å¥½çš„ hyraxAbif-exe æŒ‚è½½åˆ°å®¹å™¨ /opt/hyraxAbif/hyraxAbif-exe æ¥æ›¿ä»£æ„å»ºã€‚
	â€¢	nextflow è¿è¡Œ wf-clone-validation æ—¶ä½ å¯é€‰æ‹© -profile dockerï¼ˆéœ€è¦å®¿ä¸» Docker æƒé™ï¼‰æˆ– -profile singularity/-profile condaã€‚æˆ‘åœ¨ entrypoint ä¸­ç»™å‡ºå¸¸ç”¨è°ƒç”¨æ–¹å¼ã€‚

â¸»

2) entrypoint.sh

ä¿å­˜ä¸º entrypoint.shï¼ˆå·²åœ¨ Dockerfile COPYï¼‰ã€‚æœ¬è„šæœ¬æ˜¯å®¹å™¨å…¥å£ï¼Œè‡ªåŠ¨è¯†åˆ«å‚æ•°å¹¶æ‰§è¡Œå…¨æµç¨‹ï¼šç”Ÿæˆ samplesheet â†’ è¿è¡Œ EPI2ME workflow â†’ åˆ†ç‰‡ â†’ hyraxAbif â†’ ç”ŸæˆæŠ¥å‘Šã€‚

#!/usr/bin/env bash
set -euo pipefail

# ENTRYPOINT for plasmid-pipeline image
# Usage examples:
# docker run --rm -v /data:/data plasmid-pipeline:2.0 --fast-pass /data/fast_pass --output /data/results --project-id project1
# or
# docker run --rm -v /data:/data plasmid-pipeline:2.0 --epi2me-output /data/epi2me_out --output /data/results --project-id project1

print_help(){
  cat <<'EOF'
Plasmid-pipeline entrypoint
Options:
  --fast-pass <dir>       : path to nanopore fast_pass folder (each subfolder = sample)
  --epi2me-output <dir>   : path to wf-clone-validation output (skip assembly)
  --samplesheet <file>    : existing samplesheet.csv for wf-clone-validation
  --output <dir>          : results output directory (required)
  --project-id <id>       : project id string (optional)
  --nextflow-profile <p>  : nextflow profile (docker|conda|singularity), default: docker
  --hyrax-path <path>     : path to hyraxAbif-exe inside container (default: /opt/hyraxAbif/hyraxAbif-exe)
  --help
EOF
}

# default params
FAST_PASS=""
EPI2ME_OUT=""
SAMPLESHEET=""
OUTPUT_DIR=""
PROJECT_ID=""
NEXTFLOW_PROFILE="docker"
HYRAX_PATH="/opt/hyraxAbif/hyraxAbif-exe"

# parse args
while [[ $# -gt 0 ]]; do
  case "$1" in
    --fast-pass) FAST_PASS="$2"; shift 2;;
    --epi2me-output) EPI2ME_OUT="$2"; shift 2;;
    --samplesheet) SAMPLESHEET="$2"; shift 2;;
    --output) OUTPUT_DIR="$2"; shift 2;;
    --project-id) PROJECT_ID="$2"; shift 2;;
    --nextflow-profile) NEXTFLOW_PROFILE="$2"; shift 2;;
    --hyrax-path) HYRAX_PATH="$2"; shift 2;;
    --help) print_help; exit 0;;
    *) echo "Unknown arg: $1"; print_help; exit 1;;
  esac
done

if [[ -z "${OUTPUT_DIR}" ]]; then
  echo "[ERROR] --output <dir> is required"
  exit 1
fi

mkdir -p "${OUTPUT_DIR}"

# Step A: if fast_pass provided, generate samplesheet
if [[ -n "${FAST_PASS}" && -z "${SAMPLESHEET}" && -z "${EPI2ME_OUT}" ]]; then
  echo "[INFO] Generating samplesheet from fast_pass: ${FAST_PASS}"
  python3 /opt/pipeline/generate_samplesheet.py --fast-pass "${FAST_PASS}" --out "${OUTPUT_DIR}/samplesheet.csv"
  SAMPLESHEET="${OUTPUT_DIR}/samplesheet.csv"
fi

# Step B: Run wf-clone-validation (if no epi2me output provided)
if [[ -n "${SAMPLESHEET}" && -z "${EPI2ME_OUT}" ]]; then
  echo "[INFO] Running wf-clone-validation with samplesheet ${SAMPLESHEET}"
  # ensure wf-clone-validation is fetched by nextflow; use -profile
  nextflow run epi2me-labs/wf-clone-validation \
    --fastq "${SAMPLESHEET}" \
    --out_dir "${OUTPUT_DIR}/epi2me_output" \
    -profile "${NEXTFLOW_PROFILE}" \
    -resume
  EPI2ME_OUT="${OUTPUT_DIR}/epi2me_output"
fi

if [[ -z "${EPI2ME_OUT}" ]]; then
  echo "[ERROR] No epi2me output found or created."
  exit 1
fi

echo "[INFO] Using epi2me output at: ${EPI2ME_OUT}"

# Step C: For each sample found in epi2me output, do fragment -> ab1 -> reports
for sample_dir in "${EPI2ME_OUT}"/*; do
  if [[ ! -d "${sample_dir}" ]]; then
    continue
  fi
  sample_name=$(basename "${sample_dir}")
  echo "---------------------------------------------"
  echo "[INFO] Processing sample: ${sample_name}"
  sample_out="${OUTPUT_DIR}/${sample_name}"
  mkdir -p "${sample_out}"
  # Find assembled fasta (common names: assembly.fasta, assembly.fna, polished.fasta)
  fasta_candidate=$(ls "${sample_dir}"/*assembly*.f*a* 2>/dev/null || true)
  if [[ -z "${fasta_candidate}" ]]; then
    fasta_candidate=$(ls "${sample_dir}"/*.fasta 2>/dev/null || true)
  fi
  if [[ -z "${fasta_candidate}" ]]; then
    echo "[WARN] No assembly fasta found for ${sample_name} under ${sample_dir}"
    continue
  fi
  # take the first
  fasta_file=$(echo "${fasta_candidate}" | awk '{print $1}')
  cp -v "${fasta_file}" "${sample_out}/final.fasta"

  # fragment
  frag_dir="${sample_out}/fragments"
  mkdir -p "${frag_dir}"
  python3 /opt/pipeline/split_plasmid_fasta_v2.py --input "${sample_out}/final.fasta" --outdir "${frag_dir}" --sample "${sample_name}" --size 2000

  # generate ab1 if hyrax exists
  ab1_out="${sample_out}/ab1"
  mkdir -p "${ab1_out}"
  if [[ -x "${HYRAX_PATH}" ]]; then
    echo "[INFO] Generating AB1 files with hyraxAbif at ${HYRAX_PATH}"
    "${HYRAX_PATH}" gen "${frag_dir}" "${ab1_out}" || echo "[WARN] hyraxAbif run failed for ${sample_name}"
  else
    echo "[WARN] hyraxAbif not found at ${HYRAX_PATH}; skipping ab1 generation for ${sample_name}"
  fi

  # find fastq(s) for read length and coverage (from epi2me output mapping or original)
  # attempt to find reads under sample_dir/reads or sample_dir/fastq
  fastq_found=$(find "${sample_dir}" -type f -name "*.fastq*" | head -n1 || true)
  if [[ -z "${fastq_found}" ]]; then
    # fallback: look under parent fast_pass dir if provided
    echo "[INFO] No fastq inside epi2me output for ${sample_name}"
    fastq_found=""
  fi

  # run report generator
  python3 /opt/pipeline/generate_complete_reports_v3.py \
    --fasta "${sample_out}/final.fasta" \
    ${fastq_found:+--fastq "${fastq_found}"} \
    --outdir "${sample_out}/qc" \
    --project-id "${PROJECT_ID:-default}" \
    --sample "${sample_name}" \
    --minimap2-bin "$(command -v minimap2 || true)" \
    --samtools-bin "$(command -v samtools || true)"

  echo "[INFO] Finished sample: ${sample_name}"
done

echo "[ALL DONE] Results in ${OUTPUT_DIR}"


â¸»

3) generate_samplesheet.py

#!/usr/bin/env python3
"""
generate_samplesheet.py
Scan a fast_pass directory and produce a samplesheet.csv usable by
epi2me-labs/wf-clone-validation.

Output CSV format:
sample_id,fastq
sample1,/path/to/fastq1.fastq.gz
"""
import argparse
import csv
import glob
import os
from pathlib import Path

def discover_fast_pass(fp_dir):
    samples = {}
    for entry in os.scandir(fp_dir):
        if entry.is_dir():
            sample = entry.name
            # search for fastq.gz in the subdir
            fq_files = list(Path(entry.path).rglob("*.fastq*"))
            if fq_files:
                # join with colon separated or glob pattern; wf-clone-validation accepts glob
                samples[sample] = str(os.path.join(entry.path, "*.fastq*"))
    return samples

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--fast-pass", required=True, help="Path to fast_pass folder (each subdir a sample)")
    parser.add_argument("--out", required=True, help="Path to output samplesheet.csv")
    args = parser.parse_args()

    samples = discover_fast_pass(args.fast_pass)
    if not samples:
        print("No samples found in", args.fast_pass)
        return

    with open(args.out, "w", newline="") as csvf:
        writer = csv.writer(csvf)
        writer.writerow(["sample_id", "fastq"])
        for s, pattern in sorted(samples.items()):
            writer.writerow([s, pattern])
    print(f"[OK] Wrote {args.out} with {len(samples)} samples.")

if __name__ == "__main__":
    main()


â¸»

4) split_plasmid_fasta_v2.py

#!/usr/bin/env python3
"""
split_plasmid_fasta_v2.py

Split input fasta sequences into fragments of specified size.
Usage:
  python split_plasmid_fasta_v2.py --input sample.fasta --outdir ./frags --sample SAMPLE --size 2000
"""
import argparse
from Bio import SeqIO
import os

def split_seq(record, outdir, sample, size):
    seq = str(record.seq)
    L = len(seq)
    i = 0
    idx = 1
    while i < L:
        part = seq[i:i+size]
        fname = os.path.join(outdir, f"{sample}_{idx}.fasta")
        header = f">{sample}_part{idx} length={len(part)}"
        with open(fname, "w") as fh:
            fh.write(header + "\n")
            fh.write(part + "\n")
        print(f"[OK] Wrote {fname} ({len(part)} bp)")
        idx += 1
        i += size

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True, help="Input fasta file (may contain multiple contigs)")
    parser.add_argument("--outdir", required=True, help="Output directory for fragments")
    parser.add_argument("--sample", required=True, help="Sample name prefix for output files")
    parser.add_argument("--size", type=int, default=2000, help="Fragment size in bp (default 2000)")
    args = parser.parse_args()

    os.makedirs(args.outdir, exist_ok=True)
    records = list(SeqIO.parse(args.input, "fasta"))
    if not records:
        print("No records found in", args.input)
        return
    for rec in records:
        # if multiple contigs, append contig id
        sample_prefix = args.sample
        if len(records) > 1:
            sample_prefix = f"{args.sample}_{rec.id}"
        split_seq(rec, args.outdir, sample_prefix, args.size)

if __name__ == "__main__":
    main()


â¸»

5) generate_complete_reports_v3.py

è¿™æ˜¯å…³é”®è„šæœ¬ï¼ŒåŒ…å« coverage è®¡ç®—ï¼ˆä¼˜å…ˆä½¿ç”¨ minimap2 + samtoolsï¼Œè‹¥ç¼ºå¤±ä½¿ç”¨å†…ç½®ç®€å•æ˜ å°„å›é€€ï¼‰ã€read length distributionã€per-base breakdownã€ä»¥åŠç”Ÿæˆ PDF æŠ¥å‘Šã€‚è¯·æŠŠå®ƒä¿å­˜ä¸º generate_complete_reports_v3.pyã€‚

#!/usr/bin/env python3
"""
generate_complete_reports_v3.py

Inputs:
  --fasta <assembly.fasta>   (required)
  --fastq <reads.fastq.gz>   (optional, but recommended)
  --outdir <dir>             (required)
  --sample <sample_name>     (optional)
  --project-id <id>          (optional)
  --minimap2-bin <path>      (path to minimap2, fallback to 'minimap2' in PATH)
  --samtools-bin <path>      (path to samtools)
"""
import argparse
import os
import subprocess
from pathlib import Path
from Bio import SeqIO
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
import gzip
import sys

def run_minimap2_samtools(minimap2_bin, samtools_bin, fasta, fastq, out_bam):
    # map reads -> sort -> index -> produce coverage via samtools depth
    p1 = subprocess.run([minimap2_bin, "-ax", "map-ont", fasta, fastq], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if p1.returncode != 0:
        print("[WARN] minimap2 failed:", p1.stderr.decode()[:500])
        return False
    # write sam to temp, convert to bam
    sam = out_bam + ".unsorted.sam"
    with open(sam, "wb") as f:
        f.write(p1.stdout)
    p2 = subprocess.run([samtools_bin, "view", "-bS", sam, "-o", out_bam + ".unsorted.bam"])
    if p2.returncode != 0:
        print("[WARN] samtools view failed")
        return False
    p3 = subprocess.run([samtools_bin, "sort", "-o", out_bam, out_bam + ".unsorted.bam"])
    if p3.returncode != 0:
        print("[WARN] samtools sort failed")
        return False
    subprocess.run([samtools_bin, "index", out_bam])
    # remove intermediate
    for fn in [sam, out_bam + ".unsorted.bam"]:
        try:
            os.remove(fn)
        except:
            pass
    return True

def coverage_from_bam(samtools_bin, bam, contig):
    # returns coverage array for contig
    depth_cmd = [samtools_bin, "depth", "-a", "-r", contig, bam]
    p = subprocess.run(depth_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if p.returncode != 0:
        print("[WARN] samtools depth failed:", p.stderr.decode()[:200])
        return None
    lines = p.stdout.decode().splitlines()
    cov = []
    for line in lines:
        parts = line.split()
        # chrom pos depth
        pos = int(parts[1])
        d = int(parts[2])
        cov.append(d)
    return np.array(cov, dtype=int)

def simple_align_coverage(fasta_seq, reads_fastq, contig):
    # fallback naive: for each read, find first exact substring match (inefficient)
    # build coverage array and increment
    L = len(fasta_seq)
    cov = np.zeros(L, dtype=int)
    # read fastq
    open_fn = gzip.open if str(reads_fastq).endswith(".gz") else open
    total_reads = 0
    with open_fn(reads_fastq, "rt") as fh:
        for i, line in enumerate(fh):
            if i % 4 == 1:
                read = line.strip()
                total_reads += 1
                idx = fasta_seq.find(read[:50])  # try seed 50bp
                if idx != -1:
                    idx0 = idx
                    end = min(idx + len(read), L)
                    cov[idx0:end] += 1
    return cov

def compute_read_length_stats(fastq, out_prefix):
    # compute read lengths and save table + plot
    open_fn = gzip.open if str(fastq).endswith(".gz") else open
    lengths = []
    with open_fn(fastq, "rt") as fh:
        for i, line in enumerate(fh):
            if i % 4 == 1:
                lengths.append(len(line.strip()))
    if not lengths:
        return None
    arr = np.array(lengths)
    stats = {
        "total_reads": int(len(arr)),
        "total_bases": int(arr.sum()),
        "min": int(arr.min()), "max": int(arr.max()),
        "mean": float(arr.mean()), "median": float(np.median(arr)),
        "std": float(arr.std())
    }
    # write distribution
    counts = pd.Series(arr).value_counts().sort_index()
    dist_file = out_prefix + "_read_length_dist.txt"
    counts.to_csv(dist_file, sep="\t", header=["count"])
    # plot
    plt.figure(figsize=(8,4))
    plt.hist(arr, bins=100)
    plt.xlabel("Read Length")
    plt.ylabel("Count")
    plt.title("Read Length Distribution")
    png_file = out_prefix + "_read_length_dist.png"
    plt.tight_layout()
    plt.savefig(png_file, dpi=150)
    plt.close()
    return stats, png_file, dist_file

def coverage_plot(cov_array, out_png, contig_name):
    plt.figure(figsize=(10,3))
    x = np.arange(1, len(cov_array)+1)
    plt.plot(x, cov_array, linewidth=1)
    plt.fill_between(x, cov_array, alpha=0.2)
    avg = np.mean(cov_array) if len(cov_array)>0 else 0
    plt.title(f"Coverage: {contig_name} (avg={avg:.1f}x)")
    plt.xlabel("Position (bp)")
    plt.ylabel("Depth (x)")
    plt.tight_layout()
    plt.savefig(out_png, dpi=150)
    plt.close()

def write_per_base_csv(cov_array, out_csv, contig_name):
    df = pd.DataFrame({"position": np.arange(1, len(cov_array)+1), "depth": cov_array})
    df.to_csv(out_csv, index=False)

def create_pdf_report(pdf_path, sample, project_id, contig_name, contig_len, coverage_png, rl_png):
    c = canvas.Canvas(pdf_path, pagesize=A4)
    w, h = A4
    c.setFont("Helvetica-Bold", 14)
    c.drawString(40, h-40, f"Project: {project_id}    Sample: {sample}")
    c.setFont("Helvetica", 12)
    c.drawString(40, h-70, f"Contig: {contig_name}    Length: {contig_len} bp")
    # coverage image
    if os.path.exists(coverage_png):
        c.drawImage(coverage_png, 40, h-350, width=520, height=250, preserveAspectRatio=True)
    # read length image
    if os.path.exists(rl_png):
        c.drawImage(rl_png, 40, h-650, width=520, height=200, preserveAspectRatio=True)
    c.showPage()
    c.save()

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--fasta", required=True)
    parser.add_argument("--fastq", required=False)
    parser.add_argument("--outdir", required=True)
    parser.add_argument("--sample", default="sample")
    parser.add_argument("--project-id", default="project")
    parser.add_argument("--minimap2-bin", default="minimap2")
    parser.add_argument("--samtools-bin", default="samtools")
    args = parser.parse_args()

    os.makedirs(args.outdir, exist_ok=True)
    contigs = list(SeqIO.parse(args.fasta, "fasta"))
    if not contigs:
        print("[ERROR] No contigs found in fasta")
        sys.exit(1)
    for rec in contigs:
        contig_name = rec.id
        seq = str(rec.seq)
        contig_len = len(seq)
        print(f"[INFO] Processing contig {contig_name} ({contig_len} bp)")

        # coverage
        cov_array = None
        bam_path = os.path.join(args.outdir, f"{args.sample}_{contig_name}.bam")
        if args.fastq:
            # try minimap2 + samtools
            try:
                ok = run_minimap2_samtools(args.minimap2_bin, args.samtools_bin, args.fasta, args.fastq, bam_path)
                if ok:
                    cov_array = coverage_from_bam(args.samtools_bin, bam_path, contig_name)
            except Exception as e:
                print("[WARN] mapping pipeline failed:", e)
        if cov_array is None and args.fastq:
            print("[INFO] Falling back to naive alignment for coverage (may be slow/approximate)")
            cov_array = simple_align_coverage(seq, args.fastq, contig_name)

        if cov_array is None:
            cov_array = np.zeros(contig_len, dtype=int)

        # save per-base CSV
        per_base_csv = os.path.join(args.outdir, f"{args.sample}_{contig_name}_per_base.csv")
        write_per_base_csv(cov_array, per_base_csv, contig_name)
        # low confidence bases
        low_conf_csv = os.path.join(args.outdir, f"{args.sample}_{contig_name}_low_confidence_bases.csv")
        df = pd.read_csv(per_base_csv)
        low_df = df[df['depth'] < 3]
        low_df.to_csv(low_conf_csv, index=False)

        # coverage plot
        cov_png = os.path.join(args.outdir, f"{args.sample}_{contig_name}_coverage.png")
        coverage_plot(cov_array, cov_png, contig_name)

        # read length stats + plot
        rl_png = ""
        rl_stats = {}
        if args.fastq:
            try:
                stats, rl_png, dist_file = compute_read_length_stats(args.fastq, os.path.join(args.outdir, f"{args.sample}_{contig_name}"))
                rl_stats = stats
            except Exception as e:
                print("[WARN] read length stats failed:", e)

        # summary CSV
        summary = {
            "sample": args.sample,
            "contig": contig_name,
            "contig_len": contig_len,
            "avg_coverage": float(np.mean(cov_array)),
            "mapped_reads": int((cov_array>0).sum()),
        }
        summary_df = pd.DataFrame([summary])
        summary_csv = os.path.join(args.outdir, f"{args.sample}_{contig_name}_summary.csv")
        summary_df.to_csv(summary_csv, index=False)

        # generate pdf report
        pdf_path = os.path.join(args.outdir, f"{args.sample}_{contig_name}_report.pdf")
        create_pdf_report(pdf_path, args.sample, args.project_id, contig_name, contig_len, cov_png, rl_png)
        print(f"[OK] PDF saved: {pdf_path}")

if __name__ == "__main__":
    main()

è¯´æ˜ï¼š
	â€¢	è„šæœ¬ä¼˜å…ˆä½¿ç”¨ minimap2+samtools è¿›è¡Œæ˜ å°„è®¡ç®— coverageï¼ˆæ›´å¯é ï¼‰ã€‚å¦‚æœå®¹å™¨æˆ–å®¿ä¸»æ²¡å®‰è£…ï¼Œä¼šå›é€€åˆ°ç®€å•çš„ substring-based è¿‘ä¼¼æ˜ å°„ï¼ˆsimple_align_coverageï¼‰ï¼Œå¯¹é•¿è¯»/é«˜è¦†ç›–æ ·æœ¬è¡¨ç°ä¸å¦‚ minimap2ï¼Œä½†èƒ½ä¿è¯è„šæœ¬èƒ½è¿è¡Œã€‚
	â€¢	è„šæœ¬ä¼šç”Ÿæˆ per-base CSVã€low_confidence CSVã€coverage PNGã€read length distribution PNGã€ä»¥åŠå• contig çš„ PDF æŠ¥å‘Šã€‚

â¸»

æ„å»ºé•œåƒï¼ˆæœ¬åœ°ï¼‰

åœ¨åŒ…å«ä¸Šè¿°æ–‡ä»¶çš„ç›®å½•æ‰§è¡Œï¼š

docker build -t plasmid-pipeline:2.0 .

æ³¨æ„ï¼šé•œåƒæ„å»ºä¼šå°è¯• git clone å¹¶ç”¨ stack æ„å»º hyraxAbifã€‚å¦‚æœä½ çš„æ„å»ºç¯å¢ƒæ— æ³•è®¿é—®å¤–ç½‘ï¼ˆæˆ– S3ï¼‰ï¼Œè¯¥æ­¥éª¤ä¼šæœ‰å¤±è´¥è­¦å‘Šï¼Œä½†é•œåƒä»ä¼šæ„å»ºæˆåŠŸï¼ˆåªæ˜¯æ²¡æœ‰ç¼–è¯‘å¥½çš„ hyraxAbif-exeï¼‰ã€‚ä½ å¯ä»¥ç¨åæŠŠå·²åœ¨å…¶ä»–ç¯å¢ƒç¼–è¯‘å¥½çš„ hyraxAbif-exe æ‹·è´åˆ°å®¿ä¸»å¹¶åœ¨ docker run -v /host/path/to/hyraxAbif-exe:/opt/hyraxAbif/hyraxAbif-exe æ–¹å¼æŒ‚è½½è¿›å®¹å™¨ï¼Œentrypoint ä¼šå‘ç°å¹¶ä½¿ç”¨å®ƒã€‚

â¸»

è¿è¡Œç¤ºä¾‹
	1.	å‡è®¾å®¿ä¸»æ–‡ä»¶ç»“æ„ï¼š

/Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/fast_pass/...
/Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1/QB-template/...

	2.	è¿è¡Œ assembly + pipelineï¼ˆä½¿ç”¨ docker profile for nextflowï¼›host éœ€å…è®¸ docker-in-docker æˆ–æŠŠ nextflow é…ç½®ä¸º conda/singularityï¼‰ï¼š

docker run --rm -it \
  -v /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1:/data \
  plasmid-pipeline:2.0 \
  --fast-pass /data/fast_pass \
  --output /data/results \
  --project-id 20251031 \
  --nextflow-profile docker

å¦‚æœä½ çš„å®¿ä¸»ä¸å…è®¸å®¹å™¨å†…åˆ›å»ºæ–°çš„ docker containersï¼ˆå¸¸è§ï¼‰ï¼Œè¯·æ”¹ä¸º --nextflow-profile condaï¼ˆé•œåƒä¸­å·²è£… conda/mambaï¼‰ï¼Œå¹¶ç¡®ä¿ nextflow can use conda in container: you may need to run nextflow on host rather than inside container. å¦‚æœæ— æ³•è¿è¡Œ nextflow inside container with docker profileï¼Œå¸¸è§åšæ³•æ˜¯ï¼šåœ¨å®¿ä¸»è¿è¡Œ nextflowï¼ˆå®¿ä¸»å®‰è£… nextflowï¼‰ï¼Œè€Œå®¹å™¨åªåšåç»­æ­¥éª¤ï¼›entrypoint è„šæœ¬ä¹Ÿèƒ½æ¥å— pre-generated epi2me output via --epi2me-output.
	3.	å¦‚æœä½ å·²ç»åœ¨å®¿ä¸»å…ˆè·‘å¥½ wf-clone-validation å¹¶æŠŠè¾“å‡ºæ”¾åˆ° /data/epi2me_outputï¼Œå¯ä»¥ç›´æ¥è¿è¡Œ container åªåšåç»­å¤„ç†ï¼š

docker run --rm -it \
  -v /Volumes/Transcend/AmpSeq/19.nanopore-plasmid/20251031-new-ab1:/data \
  plasmid-pipeline:2.0 \
  --epi2me-output /data/epi2me_output \
  --output /data/results \
  --project-id 20251031


â¸»

å¸¸è§é—®é¢˜ & è§£å†³å»ºè®®
	1.	hyraxAbif æœªç¼–è¯‘æˆ–ç¼ºå°‘ hyraxAbif-exe
	â€¢	æ–¹æ¡ˆ Aï¼šåœ¨æœ‰è”ç½‘çš„æœºå™¨ä¸Šå®Œæ•´æ„å»ºé•œåƒï¼ˆèƒ½è®¿é—® Hackage/S3ï¼‰ï¼Œé•œåƒå†…ä¼šæœ‰ç¼–è¯‘å¥½çš„ hyraxAbif-exeã€‚
	â€¢	æ–¹æ¡ˆ Bï¼ˆæ¨èï¼‰ï¼šåœ¨æœºå™¨ä¸Šæœ¬åœ°ç¼–è¯‘ hyraxAbifï¼ˆä½ ä¹‹å‰å·²æˆåŠŸï¼‰ï¼ŒæŠŠ hyraxAbif-exe æ”¾åœ¨å®¿ä¸»æŸå¤„ï¼Œç„¶ååœ¨ docker run æ—¶æŒ‚è½½åˆ°å®¹å™¨å†… /opt/hyraxAbif/hyraxAbif-exeã€‚entrypoint ä¼šä½¿ç”¨å®ƒã€‚
	2.	Nextflow profile docker åœ¨å®¹å™¨å†…è¿è¡Œå¤±è´¥
	â€¢	å¸¸è§åŸå› ï¼šå®¹å™¨å†…æ— æ³•å¯åŠ¨ sibling containersã€‚å»ºè®®åœ¨å®¿ä¸»è¿è¡Œ nextflowï¼ˆhost nextflowï¼‰æˆ–ä½¿ç”¨ -profile conda/singularityã€‚æˆ‘æä¾›äº† --samplesheet ç”Ÿæˆå™¨ï¼Œæ–¹ä¾¿åœ¨å®¿ä¸»è¿è¡Œ nextflow run epi2me-labs/wf-clone-validation --fastq /path/samplesheet.csv --out_dir /path/epi2me_out -profile condaï¼Œç„¶åæŠŠ epi2me_out æŒ‚è½½åˆ°å®¹å™¨æ¥å®Œæˆåç»­æ­¥éª¤ã€‚
	3.	minimap2 / samtools not found
	â€¢	é•œåƒä½¿ç”¨ conda å®‰è£…äº† minimap2/samtoolsï¼Œè‹¥ä½ è¿è¡Œæ—¶åœ¨ host ç¯å¢ƒæ”¹åŠ¨ï¼Œè¯·ç¡®ä¿ container ä¸­èƒ½æ‰¾åˆ°å®ƒä»¬ï¼ˆwhich minimap2ï¼‰ã€‚generate script å¯æ¥å—è‡ªå®šä¹‰ --minimap2-bin/--samtools-bin è·¯å¾„ã€‚

â¸»

æˆ‘æ¥ä¸‹æ¥å¯ä»¥ç»§ç»­ä¸ºä½ åšçš„ï¼ˆå¯é€‰ï¼‰
	â€¢	æŠŠ generate_complete_reports_v3.py çš„ PDF é£æ ¼ç¾åŒ–ï¼ˆåŠ å…¥è¡¨æ ¼åˆ—ã€Assembly Status éƒ¨åˆ†ã€percentages ç­‰ï¼‰
	â€¢	æŠŠ hyraxAbif çš„æ„å»ºæ­¥éª¤æ”¹ä¸º multi-stage buildï¼šå…ˆåœ¨ builder stage å®Œæ•´ç¼–è¯‘ï¼Œå†æŠŠ hyraxAbif-exe copy åˆ°æœ€ç»ˆé•œåƒï¼ˆå‡å°‘æœ€ç»ˆé•œåƒä½“ç§¯ï¼‰
	â€¢	æŠŠ pipeline å˜æˆå¯åœ¨ Kubernetes / Slurm æäº¤çš„ä»»åŠ¡ï¼ˆæ”¯æŒæ‰¹é‡æ ·æœ¬å¹¶è¡Œï¼‰
	â€¢	æä¾›ä¸€ä¸ªå°å‹ Streamlit Web å‰ç«¯ï¼Œç”¨äºä¸Šä¼  fasta/fastq å¹¶åœ¨çº¿æŸ¥çœ‹ç”Ÿæˆçš„ AB1 + æŠ¥å‘Šï¼ˆä½ ä¹‹å‰æè¿‡æ„Ÿå…´è¶£ï¼‰

â¸»

å¦‚æœç°åœ¨ä½ åŒæ„ï¼Œæˆ‘å¯ä»¥ç«‹å³ä¸ºä½ ï¼š
	â€¢	ï¼ˆAï¼‰æŠŠè¿™äº›æ–‡ä»¶æ‰“åŒ…ä¸ºå•ä¸ª tarball æ–‡æœ¬ï¼ˆä¾›ç›´æ¥ scp ä¸Šä¼ åˆ°æœåŠ¡å™¨æ„å»ºï¼‰ï¼Œæˆ–è€…
	â€¢	ï¼ˆBï¼‰å¦‚æœä½ å¸Œæœ›æˆ‘å…ˆæœ¬åœ°æ¨¡æ‹Ÿä¸€å¥—è¿è¡Œå‘½ä»¤ï¼ˆåŸºäºä½ ä¹‹å‰æä¾›çš„ QB-template è·¯å¾„ï¼‰ï¼Œæˆ‘å¯ä»¥ç»™å‡ºç²¾ç¡®çš„ docker run çš„çœŸå®ç¤ºä¾‹ï¼ˆå¸¦è·¯å¾„æ˜ å°„ï¼‰ï¼Œå¹¶ä¸€æ­¥æ­¥è¯´æ˜å¦‚ä½•è°ƒè¯•å¸¸è§é”™è¯¯ã€‚

ä½ è¦å“ªä¸ªï¼Ÿï¼ˆå›å¤ â€œAâ€ æ‰“åŒ…æ–‡ä»¶ æˆ– â€œBâ€ ç»™å‡ºé’ˆå¯¹ä½ è·¯å¾„çš„è¿è¡Œç¤ºä¾‹ï¼‰

